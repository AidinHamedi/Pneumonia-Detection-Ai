{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model\n",
    "<pre>\n",
    " Copyright (c) 2024 Aydin Hamedi\n",
    " \n",
    " This software is released under the MIT License.\n",
    " https://opensource.org/licenses/MIT\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:44.939427800Z",
     "start_time": "2023-12-28T02:27:44.923095500Z"
    },
    "notebookRunGroups": {
     "groupValue": "213"
    }
   },
   "outputs": [],
   "source": [
    "CPU_only = False  # True to Force TF to use the cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pylibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.128539500Z",
     "start_time": "2023-12-28T02:27:44.940432900Z"
    },
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "if CPU_only:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import cv2\n",
    "import glob\n",
    "import keras\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import datetime\n",
    "import subprocess\n",
    "import gpu_control\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# import tensorflow_addons as tfa\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import *  # noqa: F403\n",
    "# from adabelief_tf import AdaBeliefOptimizer  # noqa: F401\n",
    "\n",
    "# from tensorflow_addons.optimizers import Yogi\n",
    "import keras.src.legacy.backend as K  # noqa: F401\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard, LambdaCallback, TerminateOnNaN\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    Callback,\n",
    "    LearningRateScheduler,\n",
    "    ReduceLROnPlateau,\n",
    "    SwapEMAWeights,\n",
    ")\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    GlobalAveragePooling2D,\n",
    "    concatenate,\n",
    ")\n",
    "\n",
    "# Utils\n",
    "from Utils.one_cycle import OneCycleLr\n",
    "from Utils.lr_find import LrFinder\n",
    "from Utils.Grad_cam import make_gradcam_heatmap\n",
    "from Utils.print_color_V2_NEW import print_Color_V2\n",
    "from Utils.print_color_V1_OLD import print_Color\n",
    "from Utils.Other import *  # noqa: F403\n",
    "\n",
    "# Other\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu_instance in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "from numba.cuda.cudadrv import enums\n",
    "from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "attribs = [name.replace(\"CU_DEVICE_ATTRIBUTE_\", \"\") for name in dir(enums) if name.startswith(\"CU_DEVICE_ATTRIBUTE_\")]\n",
    "\n",
    "with open(\"GPU_Info.txt\", \"w\") as f:\n",
    "    for attr in attribs:\n",
    "        f.write(f\"{attr} = {getattr(device, attr)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.139048Z",
     "start_time": "2023-12-28T02:27:47.116546100Z"
    },
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "# Directory paths# Directory paths for training, test and validation image data\n",
    "train_dir = \"Database\\\\Train\\\\Data\\\\train\"\n",
    "test_dir = \"Database\\\\Train\\\\Data\\\\test\"\n",
    "validation_dir = \"Database\\\\Train\\\\Data\\\\val\"\n",
    "img_res = [224, 224, 3]\n",
    "# img_res = [324, 324, 3]\n",
    "# img_res = [224, 224, 3]\n",
    "# img_res = [384, 384, 3] # Very slow needs >=24Gb Vram for batch size of 1 (NR!)\n",
    "interpolation_order_IFG = 2\n",
    "categorical_IMP = True\n",
    "Make_EV_DATA = False\n",
    "R_fill_mode = True\n",
    "add_img_grain = True\n",
    "Save_TS = True\n",
    "Img_Data_type = \"float16\"  # float32 / float16\n",
    "Use_SMOTE = False  # (⚠️Beta⚠️)\n",
    "ADBD = 0\n",
    "OP_HDC = False\n",
    "SL_EX = \"_V1\"  # _NONOM_V1 | _V1 | _SDNP_V1\n",
    "LNTS = 0\n",
    "Debug_OUT = False\n",
    "RANGE_NOM = True  # False for 0 to 255 True for 0 to 1 >> use False for models like ConvNeXtXLarge (⚠️deprecated⚠️)\n",
    "scale_data_NP_M = False  # (⚠️deprecated⚠️)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:48.287855100Z",
     "start_time": "2023-12-28T02:27:48.252944800Z"
    },
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_TYPE = \"H5\"\n",
    "Use_mixed_float16 = False\n",
    "# Other\n",
    "if Use_mixed_float16:\n",
    "    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "else:\n",
    "    keras.mixed_precision.set_global_policy(\"float32\")\n",
    "\n",
    "print(keras.mixed_precision.global_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.059139500Z",
     "start_time": "2023-12-28T02:27:50.219209700Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Z_SCORE_normalize\n",
    "def Z_SCORE_normalize(arr):\n",
    "    arr = arr.astype(Img_Data_type)\n",
    "    mean = np.mean(arr)\n",
    "    std_dev = np.std(arr)\n",
    "    arr = (arr - mean) / std_dev\n",
    "    return arr\n",
    "\n",
    "\n",
    "# normalize_TO_RANGE\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):\n",
    "    arr = arr.astype(Img_Data_type)\n",
    "    arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "    arr = arr * (max_val - min_val) + min_val\n",
    "    return arr\n",
    "\n",
    "\n",
    "# scale_data\n",
    "def scale_data_NP(data):\n",
    "    if scale_data_NP_M:\n",
    "        data = data.astype(Img_Data_type)\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "    else:\n",
    "        return data / 255\n",
    "\n",
    "\n",
    "# add_image_grain\n",
    "def add_image_grain(image, intensity=0.01):\n",
    "    # Generate random noise array\n",
    "    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32 if Img_Data_type == \"float32\" else \"float16\")\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "# apply_clahe_rgb_array\n",
    "def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):\n",
    "    # Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Split the image into color channels\n",
    "        b, g, r = cv2.split(images[i])\n",
    "\n",
    "        # Convert the channels to the appropriate format\n",
    "        b = cv2.convertScaleAbs(b)\n",
    "        g = cv2.convertScaleAbs(g)\n",
    "        r = cv2.convertScaleAbs(r)\n",
    "\n",
    "        # Apply adaptive histogram equalization to each channel\n",
    "        equalized_b = clahe.apply(b)\n",
    "        equalized_g = clahe.apply(g)\n",
    "        equalized_r = clahe.apply(r)\n",
    "\n",
    "        # Merge the equalized channels back into an image\n",
    "        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))\n",
    "\n",
    "        # Replace the original image with the equalized image in the array\n",
    "        images[i] = equalized_image\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# noise_func\n",
    "def noise_func(image):\n",
    "    noise_type = np.random.choice([\"L1\", \"L2\", \"L3\", \"none\"])\n",
    "    new_image = np.copy(image)\n",
    "\n",
    "    if noise_type == \"L3\":\n",
    "        intensityL2 = random.uniform(-0.05, 0.05)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.06, 0.06)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "\n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 64)\n",
    "\n",
    "    if noise_type == \"L2\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i : i + block_size_L2, j : j + block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i : i + block_size_L2, j : j + block_size_L2] = block\n",
    "        image = new_image\n",
    "\n",
    "    if noise_type == \"L1\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i : i + block_size_L1, j : j + block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i : i + block_size_L1, j : j + block_size_L1] = block\n",
    "\n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.045)  # Random intensity between 0 and 0.026\n",
    "        new_image = add_image_grain(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# shuffle_data\n",
    "def shuffle_data(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # get the class label\n",
    "        class_label = np.argmax(label)\n",
    "        # create the file path\n",
    "        file_path = os.path.join(dir_path, f\"image_{i}_class_{class_label}.png\")\n",
    "        # save the image to the file path\n",
    "        plt.imsave(file_path, image.squeeze())\n",
    "    # compress the directory\n",
    "    shutil.make_archive(dir_path, \"gztar\", dir_path)\n",
    "    # remove the original directory\n",
    "    shutil.rmtree(dir_path)\n",
    "\n",
    "\n",
    "# Debug_img_Save\n",
    "def Debug_img_Save(img, id=\"DEF\"):\n",
    "    SITD = np.random.choice(img.shape[0], size=400, replace=False)\n",
    "    S_dir = f\"Samples\\\\Debug\\\\{id}\\\\TSR_SUB_400_\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "    print_Color(f\"~*[Debug] (DPO) Sample dir: ~*{S_dir}\", [\"red\", \"green\"], advanced_mode=True)\n",
    "    save_images_to_dir(normalize_TO_RANGE(img[SITD], 0, 1), img[SITD], S_dir)\n",
    "\n",
    "\n",
    "# Create an ImageDataGenerator for the training set\n",
    "if OP_HDC:\n",
    "    print_Color(\"Using OP_HDC IDG...\", [\"yellow\"])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.24,\n",
    "        shear_range=0.22,\n",
    "        width_shift_range=0.21,\n",
    "        brightness_range=(0.86, 1.1),\n",
    "        height_shift_range=0.21,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        fill_mode=\"nearest\",  # constant\n",
    "        preprocessing_function=noise_func,\n",
    "        dtype=Img_Data_type,\n",
    "    )\n",
    "else:\n",
    "    print_Color(\"Using Def IDG...\", [\"yellow\"])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.26,\n",
    "        shear_range=0.25,\n",
    "        width_shift_range=0.25,\n",
    "        brightness_range=(0.78, 1.1),\n",
    "        height_shift_range=0.25,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        featurewise_std_normalization=False,\n",
    "        fill_mode=\"nearest\",  # constant\n",
    "        preprocessing_function=noise_func,\n",
    "        dtype=Img_Data_type,\n",
    "    )\n",
    "train_datagen_SM = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.07,\n",
    "    shear_range=0.07,\n",
    "    width_shift_range=0.07,\n",
    "    brightness_range=(0.99, 1.01),\n",
    "    height_shift_range=0.07,\n",
    "    channel_shift_range=0,\n",
    "    featurewise_center=False,\n",
    "    interpolation_order=interpolation_order_IFG,\n",
    "    featurewise_std_normalization=False,\n",
    "    dtype=Img_Data_type,\n",
    ")\n",
    "# Create an iterator for the training set\n",
    "train_generator_SM = train_datagen_SM.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_res[0], img_res[1]),\n",
    "    batch_size=sum([len(files) for r, d, files in os.walk(train_dir)]),\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "# Create an ImageDataGenerator for the validation set (OP)\n",
    "if Make_EV_DATA:\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range=0.01,\n",
    "        width_shift_range=0.01,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        dtype=Img_Data_type,\n",
    "        height_shift_range=0.01,\n",
    "    )\n",
    "\n",
    "    # Create an iterator for the validation set\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(validation_dir)]),\n",
    "        class_mode=\"binary\",\n",
    "        color_mode=\"rgb\",\n",
    "    )\n",
    "\n",
    "    # Create an ImageDataGenerator for the test set\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range=0.01,\n",
    "        width_shift_range=0.01,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        dtype=Img_Data_type,\n",
    "        height_shift_range=0.01,\n",
    "    )\n",
    "\n",
    "    # Create an iterator for the test set\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(test_dir)]),\n",
    "        class_mode=\"binary\",\n",
    "        color_mode=\"rgb\",\n",
    "    )\n",
    "# Load all images and labels into memory\n",
    "print_Color(\"Loading all images and labels into memory...\", [\"yellow\"])\n",
    "x_train, y_train = next(iter(train_generator_SM))\n",
    "if Make_EV_DATA:\n",
    "    x_val, y_val = next(iter(val_generator))\n",
    "    x_test, y_test = next(iter(test_generator))\n",
    "if Debug_OUT:\n",
    "    Debug_img_Save(x_train, \"ST1\")  # DEBUG\n",
    "# fit parameters from data\n",
    "# train_datagen.fit(x_train)\n",
    "# to_categorical (TEMP)\n",
    "if categorical_IMP:\n",
    "    print_Color(\"Making categorical data...\", [\"yellow\"])\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    if Make_EV_DATA:\n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "        y_test = to_categorical(y_test, num_classes=2)\n",
    "# Use_SMOTE\n",
    "if Use_SMOTE:\n",
    "    print_Color(\"SMOTE...\", [\"yellow\"])\n",
    "    # Convert y_train from one-hot encoding to label encoding\n",
    "    y_train_label_encoded = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Print the original label distribution\n",
    "    unique, counts = np.unique(y_train_label_encoded, return_counts=True)\n",
    "    print_Color(\n",
    "        f\"~*- Original label distribution: ~*{dict(zip(unique, counts))}\",\n",
    "        [\"normal\", \"blue\"],\n",
    "        advanced_mode=True,\n",
    "    )\n",
    "\n",
    "    # Use SMOTE to oversample the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_res, y_train_res_label_encoded = smote.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train_label_encoded)\n",
    "\n",
    "    # Print the resampled label distribution\n",
    "    unique_res, counts_res = np.unique(y_train_res_label_encoded, return_counts=True)\n",
    "    print_Color(\n",
    "        f\"~*- Resampled label distribution: ~*{dict(zip(unique_res, counts_res))}\",\n",
    "        [\"normal\", \"blue\"],\n",
    "        advanced_mode=True,\n",
    "    )\n",
    "\n",
    "    # Reshape x_train_res back to the original x_train shape\n",
    "    x_train_res = x_train_res.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "\n",
    "    # Convert y_train_res from label encoding back to one-hot encoding\n",
    "    y_train_res = to_categorical(y_train_res_label_encoded)\n",
    "\n",
    "    # Calculate the ratio of two labels after resampling\n",
    "    pneumonia_count = np.sum(y_train_res[:, 1])\n",
    "    total_count = y_train_res.shape[0]\n",
    "    label_ratio_res = pneumonia_count / total_count\n",
    "    label_ratio_percentage_res = label_ratio_res * 100\n",
    "\n",
    "    # Replace the original data with the resampled data\n",
    "    x_train = x_train_res\n",
    "    y_train = y_train_res\n",
    "\n",
    "    # Delete the resampled data to free up memory\n",
    "    del x_train_res, y_train_res_label_encoded, y_train_res\n",
    "# Generating augmented data\n",
    "print_Color(\n",
    "    f\"~*Generating augmented data ~*[~*ADBD: ~*{str(ADBD)}~*]~*...\",\n",
    "    [\"yellow\", \"cyan\", \"green\", \"red\", \"cyan\", \"yellow\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "if ADBD > 0:\n",
    "    for i in range(ADBD):\n",
    "        # ADB_clip_limit Scheduler>>>\n",
    "        if i == 0:\n",
    "            ADB_clip_limit = 0.8\n",
    "        else:\n",
    "            # V1>>>\n",
    "            CL_SLM = 2.4\n",
    "            ADB_clip_limit = max(2 / (i + 1) ** CL_SLM, 0.05)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ┌-------------┬--┬---------------┐\n",
    "            #  │ 𝑦=2/(𝑥+1)^𝑧 ├OR┤ 𝑦=2/(𝑥+1)^2.4 │\n",
    "            #  └-------------┴--┴---------------┘\n",
    "            # V2>>>\n",
    "            # CL_SLM_2 = 1.4\n",
    "            # CL_SLM_Start_2 = 2\n",
    "            # ADB_clip_limit = CL_SLM_Start_2/(i+1)**(i+CL_SLM_2)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ┌-----------------┬--┬-------------------┐\n",
    "            #  │ 𝑦=2/(𝑥+1)^(𝑥+𝑉) ├OR┤ 𝑦=2/(𝑥+1)^(𝑥+1.4) │\n",
    "            #  └-----------------┴--┴-------------------┘\n",
    "        print(f\">   Generating ADB[{i + 1}/{ADBD}]...\")\n",
    "        # prepare an iterators to scale images\n",
    "        train_iterator = train_datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "        # get augmented data\n",
    "        x_train_augmented, y_train_augmented = train_iterator.__next__()\n",
    "        print(\">   ├───Applying adaptive histogram equalization...\")\n",
    "        print(f\">   ├───Adaptive histogram equalization clip limit = {round(ADB_clip_limit, 2)}\")\n",
    "        x_train_augmented = np.clip(x_train_augmented, 0, 255)\n",
    "        if Debug_OUT:\n",
    "            Debug_img_Save(x_train_augmented, \"ST2\")  # DEBUG\n",
    "        # print_Color(f'~*>   |---Grayscale range: ~*Min = {np.min(x_train_augmented)}~* | ~*Max = {np.max(x_train_augmented)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "        x_train_augmented = apply_clahe_rgb_array(x_train_augmented, clip_limit=ADB_clip_limit)  # compensating the image info loss\n",
    "        print(\">   └───Adding the Generated ADB...\")\n",
    "        if Debug_OUT:\n",
    "            Debug_img_Save(x_train_augmented, \"ST3\")  # DEBUG\n",
    "        # append augmented data to original data\n",
    "        x_train = np.concatenate([x_train, x_train_augmented])\n",
    "        y_train = np.concatenate([y_train, y_train_augmented])\n",
    "        # free up memory\n",
    "        del y_train_augmented\n",
    "        del x_train_augmented\n",
    "# normalizing\n",
    "print_Color(\"Normalizing image data...\", [\"yellow\"])\n",
    "if Debug_OUT:\n",
    "    Debug_img_Save(x_train, \"ST4\")  # DEBUG\n",
    "x_train = np.clip(x_train, 0, 255)\n",
    "if RANGE_NOM:\n",
    "    x_train = scale_data_NP(x_train)\n",
    "y_train = np.array(y_train)\n",
    "if Make_EV_DATA:\n",
    "    x_test = np.clip(x_test, 0, 255)\n",
    "    x_val = np.clip(x_val, 0, 255)\n",
    "    if RANGE_NOM:\n",
    "        x_val = scale_data_NP(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    if RANGE_NOM:\n",
    "        x_test = scale_data_NP(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "if Debug_OUT:\n",
    "    Debug_img_Save(x_train, \"ST5\")  # DEBUG\n",
    "# Check the data type of image data\n",
    "print_Color(f\"~*Data type: ~*{x_train.dtype}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "# Check the range of image data\n",
    "print_Color(\n",
    "    f\"~*RGB Range: ~*Min = {np.min(x_train)}~* | ~*Max = {np.max(x_train)}\",\n",
    "    [\"normal\", \"blue\", \"normal\", \"red\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "# Calculate the ratio of two labels\n",
    "if categorical_IMP:\n",
    "    label_sums = np.sum(y_train, axis=0)\n",
    "    label_ratio = label_sums / (np.sum(y_train) + 1e-10)\n",
    "    label_ratio_percentage = label_ratio * 100\n",
    "    print_Color(\n",
    "        f\"~*Label ratio: ~*{100 - label_ratio_percentage[0]:.2f}% PNEUMONIA ~*| ~*{label_ratio_percentage[0]:.2f}% NORMAL\",\n",
    "        [\"normal\", \"red\", \"magenta\", \"green\"],\n",
    "        advanced_mode=True,\n",
    "    )\n",
    "print_Color(\"Setting LNTS...\", [\"yellow\"])\n",
    "# Get the total number of samples in the arrays\n",
    "num_samples = x_train.shape[0]\n",
    "print_Color(f\"~*Original num_samples: ~*{num_samples}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "if LNTS != 0:\n",
    "    print_Color(f\"~*Applying LNTS of: ~*{LNTS}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    print_Color(f\"~*SNC: ~*{num_samples - LNTS}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    # Generate random indices to select LNTS samples\n",
    "    indices = np.random.choice(num_samples, size=LNTS, replace=False)\n",
    "    # Select the samples using the generated indices\n",
    "    x_selected = x_train[indices]\n",
    "    y_selected = y_train[indices]\n",
    "    x_train = x_selected\n",
    "    y_train = y_selected\n",
    "    # free up memory\n",
    "    del x_selected\n",
    "    del y_selected\n",
    "    del indices\n",
    "    # Debug\n",
    "    num_samples = x_train.shape[0]\n",
    "    print_Color(f\"~*New num_samples: ~*{num_samples}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "# Shuffle the training data\n",
    "print_Color(\"shuffling data...\", [\"yellow\"])\n",
    "x_train, y_train = shuffle_data(x_train, y_train)\n",
    "# save_images_to_dir\n",
    "if Save_TS:\n",
    "    print_Color(\"Saving TS...\", [\"yellow\"])\n",
    "    SITD = np.random.choice(num_samples, size=400, replace=False)\n",
    "    S_dir = \"Samples/TSR400_\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "    print_Color(f\"~*Sample dir: ~*{S_dir}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    if RANGE_NOM:\n",
    "        if scale_data_NP_M:\n",
    "            save_images_to_dir((x_train[SITD] + 1) / 2.0, y_train[SITD], S_dir)\n",
    "        else:\n",
    "            save_images_to_dir(x_train[SITD], y_train[SITD], S_dir)\n",
    "    else:\n",
    "        save_images_to_dir(x_train[SITD] / 255, y_train[SITD], S_dir)\n",
    "print_Color(\"Done.\", [\"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"Database\\\\Temp\\\\Test\\\\Data\\\\x_val{SL_EX}.npy\", x_val)\n",
    "np.save(f\"Database\\\\Temp\\\\Test\\\\Data\\\\y_val{SL_EX}.npy\", y_val)\n",
    "np.save(f\"Database\\\\Temp\\\\Test\\\\Data\\\\x_test{SL_EX}.npy\", x_test)\n",
    "np.save(f\"Database\\\\Temp\\\\Test\\\\Data\\\\y_test{SL_EX}.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.380088800Z",
     "start_time": "2023-12-28T02:31:27.270860200Z"
    },
    "notebookRunGroups": {
     "groupValue": "13"
    }
   },
   "outputs": [],
   "source": [
    "x_val = np.load(f\"Database\\\\Temp\\\\Test\\\\Data\\\\x_val{SL_EX}.npy\")\n",
    "y_val = np.load(f\"Database\\\\Temp\\\\Test\\\\Data\\\\y_val{SL_EX}.npy\")\n",
    "x_test = np.load(f\"Database\\\\Temp\\\\Test\\\\Data\\\\x_test{SL_EX}.npy\")\n",
    "y_test = np.load(f\"Database\\\\Temp\\\\Test\\\\Data\\\\y_test{SL_EX}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"Database\\\\Temp\\\\Train\\\\Data\\\\train{SL_EX}.npz\", x_train=x_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = (\n",
    "    np.load(f\"Database\\\\Temp\\\\Train\\\\Data\\\\train{SL_EX}.npz\")[\"x_train\"],\n",
    "    np.load(f\"Database\\\\Temp\\\\Train\\\\Data\\\\train{SL_EX}.npz\")[\"y_train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 8, figsize=(15, 15))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow((x_train[i] * 255).astype(\"uint8\"))\n",
    "    ax.set_title(f\"Label: {np.argmax(y_train[i])}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1\n",
    "```\n",
    "recommended: ⚠️\n",
    "statuses: Ready\n",
    "Working: ✅\n",
    "Max fine tuned acc: ≅95.1\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(EfficientNetB7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "\n",
    "EfficientNet_M = EfficientNetB7(\n",
    "    include_top=True,\n",
    "    input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "    weights=None,\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)  # noqa: F405\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.1\n",
    "```\n",
    "recommended: ❌\n",
    "statuses: S.Ready (can improve)\n",
    "Working: ❌\n",
    "Max fine tuned acc: ≅93.2\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(ConvNeXtLarge)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtLarge\n",
    "\n",
    "ConvNeXtLarge_M = ConvNeXtLarge(\n",
    "    include_top=False,\n",
    "    input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "    weights=\"imagenet\",\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=False,\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=ConvNeXtLarge_M.inputs, outputs=ConvNeXtLarge_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)  # noqa: F405\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "### Rev1.2.3\n",
    "```\n",
    "recommended: ✅\n",
    "statuses: Ready\n",
    "Working: ✅\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB7::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:34:12.077394600Z",
     "start_time": "2023-12-27T17:34:05.068171500Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"noisy-student\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL>>>\n",
    "    # GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name=\"FC_INPUT_Avg-Pooling\")(base_model.output)\n",
    "    # Dense\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.0026), name=\"FC_C_Dense-L1-512\")(base_model_FT)\n",
    "    # Dropout\n",
    "    Dropout_L1 = Dropout(0.125, name=\"FC_C_Dropout-L1-0.1\")(Dense_L1)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L1\")(Dropout_L1)\n",
    "    # Dense\n",
    "    Dense_L2 = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.0015), name=\"FC_C_Dense-L2-512\")(BatchNorm_L2)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L2\")(Dense_L2)\n",
    "    # Dense\n",
    "    Dense_L3 = Dense(128, activation=\"relu\", name=\"FC_C_Dense-L3-128\")(BatchNorm_L3)\n",
    "    # Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"FC_OUTPUT_Dense-2\")(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False, use_ema=True)  # noqa: F405\n",
    "    # opt = Nadam() # noqa: F405\n",
    "    # opt = Adamax() # noqa: F405\n",
    "    # opt = Adam(amsgrad=True) # noqa: F405\n",
    "    # opt = RMSprop(momentum=0.9) # noqa: F405\n",
    "    # opt = Adagrad() # noqa: F405\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, amsgrad=True)  # noqa: F405\n",
    "    # opt = Yogi() # noqa: F405\n",
    "    model_EfficientNetB7_NS.compile(\n",
    "        optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.3\n",
    "```\n",
    "recommended: ❌\n",
    "statuses: Test\n",
    "Working: ✅\n",
    "Max fine tuned acc: ⚠️\n",
    "Max fine tuned acc TLRev2: ⚠️\n",
    "type: transfer learning>>>(EfficientNetB7|Xception::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Combo_Model(freeze_layers1, freeze_layers2):\n",
    "    # Define a common input\n",
    "    common_input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "\n",
    "    # Base model 1\n",
    "    base_model1 = KENB7(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"noisy-student\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\EfficientNetB7_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model1_out = base_model1(common_input)\n",
    "\n",
    "    # Base model 2\n",
    "    base_model2 = Xception(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\Xception_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model2_out = base_model2(common_input)\n",
    "\n",
    "    print(\"Total base_model1 layers: \", len(base_model1.layers))\n",
    "    print(\"Total base_model2 layers: \", len(base_model2.layers))\n",
    "\n",
    "    # Freeze the specified number of layers in both models\n",
    "    for layer in base_model1.layers[:freeze_layers1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model2.layers[:freeze_layers2]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest in both models\n",
    "    for layer in base_model1.layers[freeze_layers1:]:\n",
    "        layer.trainable = True\n",
    "    for layer in base_model2.layers[freeze_layers2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Combine the output of the two base models\n",
    "    combined = concatenate(\n",
    "        [\n",
    "            Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(GlobalAveragePooling2D()(base_model1_out)),\n",
    "            Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(GlobalAveragePooling2D()(base_model2_out)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # adding CDL\n",
    "    Dense_L1 = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.02))(combined)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.003))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    combo_model = Model(inputs=common_input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(combo_model.layers))\n",
    "\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)  # noqa: F405\n",
    "    combo_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return combo_model\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers_1 = 0\n",
    "freeze_layers_2 = 0\n",
    "model = Combo_Model(freeze_layers_1, freeze_layers_2)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.4\n",
    "```\n",
    "recommended: ⚠️\n",
    "statuses: Test\n",
    "Working: ✅\n",
    "Max fine tuned acc: ⚠️\n",
    "Max fine tuned acc TLRev2: ≅95.64\n",
    "type: transfer learning>>>(EfficientNetV2XL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_efficientnet_v2 import EfficientNetV2XL\n",
    "\n",
    "EfficientNet_M = EfficientNetV2XL(\n",
    "    input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "    pretrained=\"imagenet21k-ft1k\",\n",
    "    num_classes=2,\n",
    "    dropout=0.4,\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)  # noqa: F405\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-2, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "freeze_layers = 0\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.5.2 (The best one)\n",
    "```\n",
    "recommended: ✅\n",
    "statuses: Ready\n",
    "Working: ✅\n",
    "Max fine tuned acc: 95.54\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB4::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB4 as KENB4\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B4_NS(freeze_layers):\n",
    "    base_model = KENB4(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"noisy-student\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL>>>\n",
    "    # GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name=\"FC_INPUT_Avg-Pooling\")(base_model.output)\n",
    "    # Dense\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.0086), name=\"FC_C_Dense-L1-512\")(base_model_FT)\n",
    "    # Dropout\n",
    "    Dropout_L1 = Dropout(0.125, name=\"FC_C_Dropout-L1-0.1\")(Dense_L1)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L1\")(Dropout_L1)\n",
    "    # Dense\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.0065), name=\"FC_C_Dense-L2-512\")(BatchNorm_L2)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L2\")(Dense_L2)\n",
    "    # Dense\n",
    "    Dense_L3 = Dense(128, activation=\"relu\", name=\"FC_C_Dense-L3-128\")(BatchNorm_L3)\n",
    "    # Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"FC_OUTPUT_Dense-2\")(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB4_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB4_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.95, nesterov=False)  # noqa: F405\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB4_NS.compile(\n",
    "        optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB4_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B4_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.6 \n",
    "```\n",
    "recommended: ✅\n",
    "statuses: Ready\n",
    "Working: ✅\n",
    "Max fine tuned acc: 96.47\n",
    "type: transfer learning>>>(EfficientNetB0::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB0 as KENB0\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B0_NS(freeze_layers):\n",
    "    base_model = KENB0(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"noisy-student\",\n",
    "        include_top=False,\n",
    "    )\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL>>>\n",
    "    # GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name=\"FC_INPUT_Avg-Pooling\")(base_model.output)\n",
    "    # Dense\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02), name=\"FC_C_Dense-L1-512\")(base_model_FT)\n",
    "    # Dropout\n",
    "    Dropout_L1 = Dropout(0.1, name=\"FC_C_Dropout-L1-0.1\")(Dense_L1)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L1\")(Dropout_L1)\n",
    "    # Dense\n",
    "    Dense_L2 = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.01), name=\"FC_C_Dense-L2-512\")(BatchNorm_L2)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L2\")(Dense_L2)\n",
    "    # Dense\n",
    "    Dense_L3 = Dense(128, activation=\"relu\", name=\"FC_C_Dense-L3-128\")(BatchNorm_L3)\n",
    "    # Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"FC_OUTPUT_Dense-2\")(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB0_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB0_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.92, nesterov=False)  # noqa: F405\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB0_NS.compile(\n",
    "        optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB0_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B0_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetL2 as KENBL2\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENBL2(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=\"./download/Models/EFN_L2/efficientnet-l2_noisy-student_notop.h5\",\n",
    "        include_top=False,\n",
    "        drop_connect_rate=0,\n",
    "    )\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model.output)\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)  # noqa: F405\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:32.994176700Z",
     "start_time": "2023-12-28T02:31:27.381088600Z"
    }
   },
   "outputs": [],
   "source": [
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=None,\n",
    "        include_top=False,\n",
    "    )\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL>>>\n",
    "    # GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name=\"FC_INPUT_Avg-Pooling\")(base_model.output)\n",
    "    # Dense\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02), name=\"FC_C_Dense-L1-512\")(base_model_FT)\n",
    "    # Dropout\n",
    "    Dropout_L1 = Dropout(0.1, name=\"FC_C_Dropout-L1-0.1\")(Dense_L1)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name=\"FC_C_Avg-Pooling-L1\")(Dropout_L1)\n",
    "    # Dense\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01), name=\"FC_C_Dense-L2-512\")(BatchNorm_L2)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name=\"FC_C_Avg-Pooling-L2\")(Dense_L2)\n",
    "    # Dense\n",
    "    Dense_L3 = Dense(128, activation=\"relu\", name=\"FC_C_Dense-L3-128\")(BatchNorm_L3)\n",
    "    # Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"FC_OUTPUT_Dense-2\")(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)  # noqa: F405\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(\n",
    "        optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtXLarge\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B7_NS():\n",
    "    # Add a Lambda layer at the beginning to scale the input\n",
    "    input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "    x = Lambda(lambda image: image * 255)(input)\n",
    "\n",
    "    base_model = ConvNeXtXLarge(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        classes=2,\n",
    "        classifier_activation=\"softmax\",\n",
    "        include_preprocessing=True,\n",
    "    )(x)\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model)\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)  # noqa: F405\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "model = Eff_B7_NS()\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "# FUNC\n",
    "def Eff_B7_NS():\n",
    "    base_model = EfficientNetB7(\n",
    "        input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "        weights=None,\n",
    "        include_top=False,\n",
    "    )\n",
    "    base_model.load_weights(\"download\\Models\\efficientnet-b7_noisy-student_notop.h5\", skip_mismatch=True, by_name=True)\n",
    "    # adding CDL>>>\n",
    "    # GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name=\"FC_INPUT_Avg-Pooling\")(base_model.output)\n",
    "    # Dense\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.0026), name=\"FC_C_Dense-L1-512\")(base_model_FT)\n",
    "    # Dropout\n",
    "    Dropout_L1 = Dropout(0.125, name=\"FC_C_Dropout-L1-0.1\")(Dense_L1)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L1\")(Dropout_L1)\n",
    "    # Dense\n",
    "    Dense_L2 = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.0015), name=\"FC_C_Dense-L2-512\")(BatchNorm_L2)\n",
    "    # BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name=\"FC_C_Avg-BatchNormalization-L2\")(Dense_L2)\n",
    "    # Dense\n",
    "    Dense_L3 = Dense(128, activation=\"relu\", name=\"FC_C_Dense-L3-128\")(BatchNorm_L3)\n",
    "    # Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"FC_OUTPUT_Dense-2\")(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False, use_ema=True)  # noqa: F405\n",
    "    # opt = Nadam() # noqa: F405\n",
    "    # opt = Adamax() # noqa: F405\n",
    "    # opt = Adam(amsgrad=True) # noqa: F405\n",
    "    # opt = RMSprop(momentum=0.9) # noqa: F405\n",
    "    # opt = Adagrad() # noqa: F405\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, amsgrad=True)  # noqa: F405\n",
    "    # opt = Yogi() # noqa: F405\n",
    "    model_EfficientNetB7_NS.compile(\n",
    "        optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS()\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "keras.backend.clear_session()\n",
    "# CONF/Other\n",
    "LRF_OPT = SGD(momentum=0.92)  # noqa: F405\n",
    "LFR_batch_size = 16  # or any other batch size that fits in your memory\n",
    "# Data prep\n",
    "num_samples = x_train.shape[0]\n",
    "SITD = np.random.choice(num_samples, size=4096, replace=False)\n",
    "LRF_dataset = tf.data.Dataset.from_tensor_slices((x_train[SITD], y_train[SITD])).batch(LFR_batch_size)\n",
    "# Instantiate LrFinder\n",
    "lr_find = LrFinder(model, LRF_OPT, tf.keras.losses.categorical_crossentropy)\n",
    "\n",
    "# Start range_test\n",
    "lr_find.range_test(LRF_dataset, end_lr=0.9, num_iter=256, beta=0.8)\n",
    "lr_find.plot_lrs(skip_end=0, suggestion=True, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = \"model_1.png\"\n",
    "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PRMC = False\n",
    "freeze_from_opposite = False\n",
    "Extra_EXT = \"_T\"\n",
    "freeze_layers = 0\n",
    "randomly_frozen_layers = 0\n",
    "freeze_last_seven = False\n",
    "# CEC_opt = Adagrad()\n",
    "# CEC_opt = Yogi()\n",
    "# CEC_opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "CEC_opt = SGD(momentum=0.99, learning_rate=0.001, nesterov=False)  # noqa: F405\n",
    "# CEC_opt = Adam()\n",
    "# Main\n",
    "try:\n",
    "    if SAVE_TYPE == \"TF\":\n",
    "        model = load_model(f\"PAI_model{Extra_EXT}\", compile=PRMC)\n",
    "    else:\n",
    "        model = load_model(f\"PAI_model{Extra_EXT}.h5\", compile=PRMC)\n",
    "except (ImportError, IOError) as e:\n",
    "    print(f\"\\033[91mfailed to load the model ERROR:\\n{e}\")\n",
    "else:\n",
    "    print(\"\\033[92mLoading model done.\")\n",
    "    if not PRMC:\n",
    "        print(\"Compiling the AI model...\\033[0m\")\n",
    "\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Select random layers to freeze\n",
    "        frozen_layer_indices = random.sample(range(len(model.layers)), randomly_frozen_layers)\n",
    "\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i in frozen_layer_indices:\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                if freeze_from_opposite and (i > len(model.layers) - freeze_layers):\n",
    "                    layer.trainable = False\n",
    "                elif (not freeze_from_opposite) and i < freeze_layers:\n",
    "                    layer.trainable = False\n",
    "                else:\n",
    "                    layer.trainable = True\n",
    "\n",
    "        for layer in model.layers[-7:]:\n",
    "            layer.trainable = not freeze_last_seven\n",
    "\n",
    "        model.compile(optimizer=CEC_opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.summary(show_trainable=True, expand_nested=True)\n",
    "        print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"PAI_model_weights.h5\")\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[-7:]:\n",
    "    if hasattr(layer, \"kernel_initializer\") and hasattr(layer, \"bias_initializer\"):\n",
    "        weight_initializer = layer.kernel_initializer\n",
    "        bias_initializer = layer.bias_initializer\n",
    "\n",
    "        old_weights, old_biases = layer.get_weights()\n",
    "\n",
    "        layer.set_weights(\n",
    "            [\n",
    "                weight_initializer(shape=old_weights.shape),\n",
    "                bias_initializer(shape=len(old_biases)),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreeze all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev2 (THE BEST)\n",
    "```\n",
    "Working: ✅\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " + Perverts overfitting.\n",
    " + Lower memory usage.\n",
    " - Slow training.\n",
    " + Achieving higher acc.\n",
    " - Unstable training.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:23.573633300Z",
     "start_time": "2023-12-28T02:31:32.468641900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\u001b[0;33m\n",
      "Setup Verbose:\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mExperiment name: \u001b[0m\u001b[0;32m[EPRT-Keras3-torch_y2024_m03_d24-h15_m49_s00]\u001b[0m\u001b[0;36m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSetting TensorBoard Log dir to \u001b[0m\u001b[0;32m[logs/fit/EPRT-Keras3-torch_y2024_m03_d24-h15_m49_s00]\u001b[0m\u001b[0;36m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_extended_tensorboard \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_SwapEMAWeights \u001b[0m\u001b[0;32m[True]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mDebug_OUTPUT_DPS \u001b[0m\u001b[0;32m[True]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_OneCycleLr \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUsing the modified ReduceLROnPlateau.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mOneCycleLr_UFTS \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mOptimizer: \u001b[0m\u001b[0;32mSGD\u001b[0m\n",
      "\u001b[0;36m <Opt> Parameters:\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mname: \u001b[0m\u001b[0;32mSGD\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mlearning_rate: \u001b[0m\u001b[0;32m0.009999999776482582\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mweight_decay: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mclipnorm: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mglobal_clipnorm: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mclipvalue: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96muse_ema: \u001b[0m\u001b[0;32mTrue\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mema_momentum: \u001b[0m\u001b[0;32m0.99\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mema_overwrite_frequency: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mloss_scale_factor: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mgradient_accumulation_steps: \u001b[0m\u001b[0;32mNone\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mmomentum: \u001b[0m\u001b[0;32m0.9\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36m <Opt> -- \u001b[0m\u001b[0;96mnesterov: \u001b[0m\u001b[0;32mFalse\u001b[0m\n",
      "\u001b[0;33mSetup Verbose END.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m1\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 0)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Stage 1]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Loading fitted ImageDataGenerator...\u001b[0m\n",
      "\u001b[0;33m- ImageDataGenerator fit done.\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m03_d24-h15_m50_s07\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 763ms/step - accuracy: 0.8940 - loss: 0.9525 - val_accuracy: 0.9311 - val_loss: 0.7995 - learning_rate: 0.0100\n",
      "Epoch 2/6\n",
      "\u001b[1m102/256\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 717ms/step - accuracy: 0.9371 - loss: 0.7039"

     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "keras.backend.clear_session()\n",
    "# CONF <-------------------------------------------------------------------------->\n",
    "# Hyperparameters for training the model:\n",
    "max_epoch = 489  # max_epoch: Maximum number of epochs to train for. Use >=256 for full fine-tuning of large models.\n",
    "max_EST_epoch = 164  # max_EST_epoch: Maximum number epochs to trian the model estimation for the One Cycle UFTS.\n",
    "subset_epoch = 6  # subset_epoch: Number of epochs to train each subset.\n",
    "subset_epoch_FT = 6  # subset_epoch_FT: subset_epoch after pre-training epochs.\n",
    "Stage1_epoch = 26  # Stage1_epoch: Number of pre-training epochs. Use >=24 for large models or 0/1 for fine-tuning only.\n",
    "subset_size = 4096  # subset_size: Size of each training subset. Common values: 512, 1024, 2048, 3200, 4096, 5846, 8192.\n",
    "Conf_batch_size_REV2 = 16  # Conf_batch_size_REV2: Batch size.\n",
    "RES_Train = False  # RES_Train: Resume training if True.\n",
    "STR_M = 0.9  # STR_M: Starting momentum.\n",
    "STR_LR = 0.01  # STR_LR: Starting learning rate.\n",
    "MAX_LR = 0.01  # MAX_LR: Maximum learning rate.\n",
    "DEC_LR = 0.00005  # DEC_LR: Learning rate decay.\n",
    "MIN_LR = 0.0005  # MIN_LR: Minimum learning rate.\n",
    "RES_LR = 0.006  # RES_LR: Resuming learning rate.\n",
    "ReduceLROnPlateau_factor = 0.982  # ReduceLROnPlateau_factor: ReduceLROnPlateau factor. (Lr = Factor * Lr_prev)\n",
    "ReduceLROnPlateau_patience = 10  # ReduceLROnPlateau_patience: ReduceLROnPlateau patience. (pt = ReduceLROnPlateau_patience * subset_epochs)\n",
    "Use_OneCycleLr = False  # Use_OneCycleLr: Use OneCycleLr if True. if false, use ReduceLROnPlateau.\n",
    "OneCycleLr_UFTS = False  # OneCycleLr_UFTS: Set the OneCycleLr max epochs to the estimated full training SUB epochs. (DEC_LR and MIN_LR dont have any effect if True)\n",
    "Debug_OUTPUT_DPS = True  # Debug_OUTPUT_DPS: Output debug image samples if True.\n",
    "Debug_OUTPUT_DPS_freq = 42  # Debug_OUTPUT_DPS_freq: Debug image output frequency(epoch).\n",
    "TerminateOnHighTemp_M = True  # TerminateOnHighTemp_M: Terminate training on high GPU temp to prevent damage. (Can make the training slower)\n",
    "SAVE_FULLM = True  # SAVE_FULLM: Save full model if True.\n",
    "Use_SwapEMAWeights = True  # Use_SwapEMAWeights: Use EMA weights swapping if True.\n",
    "AdvSubsetC = True  # AdvSubsetC: Use advanced subset sampling to prevent overfitting if True.\n",
    "AdvSubsetC_SHR = 42  # AdvSubsetC_SHR: Parameter for advanced subset sampling (shuffling data after n epochs).\n",
    "load_SUB_BRW = True  # load_SUB_BRW: Load previous subset weights to speed up training if True. May reduce max accuracy.\n",
    "load_SUB_BRW_MODE = \"val_accuracy\"  # load_SUB_BRW_MODE: Previous subset weights loading mode - 'val_accuracy' or 'val_loss'.\n",
    "load_SUB_BRW_LMODE = 0  # load_SUB_BRW_LMODE: Previous subset weights loading mode parameter (1 for only on imp and !1 for normal mode (for subset_epoch > 6 normal mode is better)).\n",
    "load_SUB_BRW_LMODE_FN = True  # load_SUB_BRW_LMODE_FN: Set load_SUB_BRW_LMODE=1 during fine-tuning if True.\n",
    "ModelCheckpoint_mode = \"auto\"  # ModelCheckpoint_mode: 'auto', 'min', or 'max' - how to monitor ModelCheckpoint.\n",
    "ModelCheckpoint_Reset_TO = 0.6251  # ModelCheckpoint_Reset_TO: Reset ModelCheckpoint monitor to this value, e.g. 0 or float('inf').\n",
    "Auto_clear_cache = True  # Auto_clear_cache: Clear cache during training if True to reduce memory usage.\n",
    "Use_ES_ONSUBT = False  # Use_ES_ONSUBT: Early stopping per subset (⚠️deprecated⚠️).\n",
    "EarlyStopping_P = 5  # EarlyStopping_P: Early stopping patience (⚠️deprecated⚠️).\n",
    "Use_tensorboard_profiler = False  # Use_tensorboard_profiler: Enable tensorboard profiler.\n",
    "Use_extended_tensorboard = False  # Use_extended_tensorboard: Enable extended tensorboard (Some funcs may not work).\n",
    "Use_tensorBoard_img = False  # Use_tensorBoard_img: Enable tensorboard image logging.\n",
    "Show_confusion_matrix_tensorBoard = False  # Show_confusion_matrix_tensorBoard: Show confusion matrix on tensorboard.\n",
    "BEST_RSN = \"PAI_model_T\"  # Best model save name prefix. (Uses a lot of memory and storage).\n",
    "ALWAYS_REFIT_IDG = 0  # ALWAYS_REFIT_IDG: if 0/False - do not always refit IDG. if 1 - always refit IDG (In Start). if 2 - always refit IDG (After each epoch) (slow).\n",
    "IDG_FitP_PATH = \"Data\\\\image_SUB_generator.pkl\"\n",
    "Catch_Fit_Err = True # Catch_Fit_Err: Catch fit error if True.\n",
    "Experiment_EXT = input(\"Experiment name: \")  # Experiment_EXT: Experiment name extension.\n",
    "# CONF END <---------------------------------------------------------------------->\n",
    "# Prep\n",
    "if RES_Train:\n",
    "    MAX_LR = RES_LR\n",
    "    Stage1_epoch = 1\n",
    "EXPR_name = f\"{Experiment_EXT}_\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "set_optimizer_attribute(model.optimizer, \"learning_rate\", STR_LR, verbose=True)  # noqa: F405\n",
    "set_optimizer_attribute(model.optimizer, \"momentum\", STR_M, verbose=True)  # noqa: F405\n",
    "# VAR\n",
    "Total_SUB_epoch_C = 0  # TO FIX TensorBoard\n",
    "CU_LR = MAX_LR\n",
    "all_histories = []\n",
    "chosen_indices = []\n",
    "subset_sizes = []\n",
    "best_acc = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "# apply_clahe_rgb_array\n",
    "def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):  # noqa: F811\n",
    "    # Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Split the image into color channels\n",
    "        b, g, r = cv2.split(images[i])\n",
    "\n",
    "        # Convert the channels to the appropriate format\n",
    "        b = cv2.convertScaleAbs(b)\n",
    "        g = cv2.convertScaleAbs(g)\n",
    "        r = cv2.convertScaleAbs(r)\n",
    "\n",
    "        # Apply adaptive histogram equalization to each channel\n",
    "        equalized_b = clahe.apply(b)\n",
    "        equalized_g = clahe.apply(g)\n",
    "        equalized_r = clahe.apply(r)\n",
    "\n",
    "        # Merge the equalized channels back into an image\n",
    "        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))\n",
    "\n",
    "        # Replace the original image with the equalized image in the array\n",
    "        images[i] = equalized_image\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):  # noqa: F811\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # get the class label\n",
    "        class_label = np.argmax(label)\n",
    "        # create the file path\n",
    "        file_path = os.path.join(dir_path, f\"image_{i}_class_{class_label}.png\")\n",
    "        # save the image to the file path\n",
    "        plt.imsave(file_path, image.squeeze())\n",
    "    # compress the directory\n",
    "    shutil.make_archive(dir_path, \"gztar\", dir_path)\n",
    "    # remove the original directory\n",
    "    shutil.rmtree(dir_path)\n",
    "\n",
    "\n",
    "# shuffle_data\n",
    "def shuffle_data(x, y):  # noqa: F811\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Funcs\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):  # noqa: F811\n",
    "    arr = arr.astype(\"float32\")\n",
    "    arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "    arr = arr * (max_val - min_val) + min_val\n",
    "    return arr\n",
    "\n",
    "\n",
    "def Z_SCORE_normalize(arr):  # noqa: F811\n",
    "    arr = arr.astype(\"float32\")\n",
    "    mean = np.mean(arr)\n",
    "    std_dev = np.std(arr)\n",
    "    arr = (arr - mean) / std_dev\n",
    "    return arr\n",
    "\n",
    "\n",
    "def add_image_grain_TRLRev2(image, intensity=0.01):\n",
    "    # Generate random noise array\n",
    "    noise = (\n",
    "        np.random.randint(-255, 255, size=image.shape, dtype=np.int16) + np.random.randint(-255, 255, size=image.shape, dtype=np.int16)\n",
    "    ) / 2\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "# noise_func_TRLRev2\n",
    "def noise_func_TRLRev2(image):\n",
    "    noise_type = np.random.choice([\"L1\", \"L2\", \"L3\", \"none\"])\n",
    "    new_image = np.copy(image)\n",
    "\n",
    "    if noise_type == \"L3\":\n",
    "        intensityL2 = random.uniform(-0.08, 0.08)\n",
    "        intensityL1 = random.uniform(-0.05, 0.05)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.09, 0.09)\n",
    "        intensityL1 = random.uniform(-0.06, 0.06)\n",
    "\n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 112)\n",
    "\n",
    "    if noise_type == \"L2\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i : i + block_size_L2, j : j + block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i : i + block_size_L2, j : j + block_size_L2] = block\n",
    "        image = new_image\n",
    "\n",
    "    if noise_type == \"L1\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i : i + block_size_L1, j : j + block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i : i + block_size_L1, j : j + block_size_L1] = block\n",
    "\n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.07)  # Random intensity\n",
    "        new_image = add_image_grain_TRLRev2(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# CONST\n",
    "train_SUB_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=179,\n",
    "    zoom_range=0.16,\n",
    "    shear_range=0.16,\n",
    "    width_shift_range=0.16,\n",
    "    brightness_range=(0.802, 1.198),\n",
    "    height_shift_range=0.16,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    zca_whitening=False,\n",
    "    interpolation_order=2,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=noise_func_TRLRev2,\n",
    ")\n",
    "\n",
    "\n",
    "class TerminateOnHighTemp(Callback):\n",
    "    def __init__(self, check_every_n_batches=2, high_temp=75, low_temp=60, pause_time=60):\n",
    "        super().__init__()\n",
    "        self.check_every_n_batches = check_every_n_batches\n",
    "        self.high_temp = high_temp\n",
    "        self.low_temp = low_temp\n",
    "        self.pause_time = pause_time\n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.check_every_n_batches == 0:\n",
    "            temperature = gpu_control.get_temperature()\n",
    "            if temperature > self.high_temp:\n",
    "                print_Color(\n",
    "                    f\"\\nPausing training due to high GPU temperature! (for [{self.pause_time}]sec)\",\n",
    "                    [\"red\"],\n",
    "                    advanced_mode=False,\n",
    "                )\n",
    "                time.sleep(self.pause_time)\n",
    "                while gpu_control.get_temperature() > self.low_temp:\n",
    "                    time.sleep(4)\n",
    "                print_Color(\"Resuming training...\", [\"yellow\"])\n",
    "\n",
    "\n",
    "class ExtendedTensorBoard(TensorBoard):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs[\"lr\"] = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        logs[\"momentum\"] = self.model.optimizer.momentum\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "\n",
    "class DummyCallback(Callback):\n",
    "    pass\n",
    "\n",
    "\n",
    "def DummyFunc(*Dummy_args, **Dummy_kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Define a function to plot the confusion matrix\n",
    "def plot_confusion_matrix_TensorBoard(epoch, logs):\n",
    "    # Use the model to predict the values from the test dataset.\n",
    "    test_pred_raw = model.predict(x_test, verbose=0)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)  # Convert predictions from one-hot encoded to binary\n",
    "\n",
    "    # Convert true labels from one-hot encoded to binary\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(y_true, test_pred)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    # Add image summary\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", image, step=epoch)\n",
    "\n",
    "\n",
    "# steps_per_epoch_train_SUB\n",
    "steps_per_epoch_train_SUB = subset_size // Conf_batch_size_REV2\n",
    "# callbacks>>>\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=EarlyStopping_P,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "# ModelCheckpoint\n",
    "checkpoint_SUB = ModelCheckpoint(\n",
    "    f\"cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.weights.h5\",  # f'cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.h5',\n",
    "    monitor=load_SUB_BRW_MODE,\n",
    "    save_best_only=True,\n",
    "    mode=ModelCheckpoint_mode,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "# TerminateOnHighTemp\n",
    "TerminateOnHighTemp_CB = TerminateOnHighTemp(check_every_n_batches=6, high_temp=73, low_temp=58, pause_time=60)\n",
    "# confusion_matrix_callback\n",
    "confusion_matrix_callback = LambdaCallback(on_epoch_end=plot_confusion_matrix_TensorBoard)\n",
    "# TensorBoard\n",
    "log_dir = f\"logs/fit/{EXPR_name}\"\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"\\\\Data\")\n",
    "if Use_extended_tensorboard:\n",
    "    tensorboard_callback = ExtendedTensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img,\n",
    "        histogram_freq=1,\n",
    "        update_freq=\"epoch\",\n",
    "        write_graph=True,\n",
    "        profile_batch=\"128,138\" if Use_tensorboard_profiler else 0,\n",
    "    )\n",
    "else:\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img,\n",
    "        histogram_freq=1,\n",
    "        update_freq=\"epoch\",\n",
    "        write_graph=True,\n",
    "        profile_batch=\"128,138\" if Use_tensorboard_profiler else 0,\n",
    "    )\n",
    "# OneCycleLr\n",
    "if OneCycleLr_UFTS and Use_OneCycleLr:\n",
    "    learning_rate_schedule_SUB = OneCycleLr(\n",
    "        max_lr=MAX_LR,\n",
    "        steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "        epochs=(Stage1_epoch * subset_epoch) + ((max_EST_epoch - Stage1_epoch) * subset_epoch_FT),\n",
    "    )\n",
    "# ReduceLROnPlateau\n",
    "if not Use_OneCycleLr:\n",
    "    learning_rate_schedule_SUB = ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\",\n",
    "        factor=ReduceLROnPlateau_factor,\n",
    "        cooldown=subset_epoch,\n",
    "        patience=subset_epoch * ReduceLROnPlateau_patience,\n",
    "        min_lr=MIN_LR,\n",
    "        verbose=1,\n",
    "    )\n",
    "    learning_rate_schedule_SUB.on_train_begin = DummyFunc  # Remove on_train_begin to make it work with subset training.\n",
    "# SwapEMAWeights\n",
    "SwapEMAWeights_callback = SwapEMAWeights(swap_on_epoch=True)\n",
    "# TerminateOnNaN\n",
    "TerminateOnNaN_callback = TerminateOnNaN()\n",
    "# PRES\n",
    "callbacks_active = {\n",
    "    \"learning_rate_schedule_SUB\": True,\n",
    "    \"TerminateOnHighTemp_CB\": TerminateOnHighTemp_M,\n",
    "    \"checkpoint_SUB\": load_SUB_BRW,\n",
    "    \"early_stopping\": Use_ES_ONSUBT,\n",
    "    \"tensorboard_callback\": True,\n",
    "    \"confusion_matrix_callback\": Show_confusion_matrix_tensorBoard,\n",
    "    \"TerminateOnNaN_callback\": True,\n",
    "    \"SwapEMAWeights_callback\": Use_SwapEMAWeights,\n",
    "}\n",
    "# MAIN\n",
    "print(\"Training the model...\")\n",
    "# INFOp\n",
    "print_Color(\"\\nSetup Verbose:\", [\"yellow\"])\n",
    "print_Color(\n",
    "    f\"~*Experiment name: ~*[{EXPR_name}]~*...\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\n",
    "    f\"~*Setting TensorBoard Log dir to ~*[{log_dir}]~*...\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\n",
    "    f\"~*Use_extended_tensorboard ~*[{Use_extended_tensorboard}]~*.\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\n",
    "    f\"~*Use_SwapEMAWeights ~*[{Use_SwapEMAWeights}]~*.\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\n",
    "    f\"~*Debug_OUTPUT_DPS ~*[{Debug_OUTPUT_DPS}]~*.\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\n",
    "    f\"~*Use_OneCycleLr ~*[{Use_OneCycleLr}]~*.\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "if not Use_OneCycleLr:\n",
    "    print_Color(\"~*Using the modified ReduceLROnPlateau.\", [\"cyan\"], advanced_mode=True)\n",
    "print_Color(\n",
    "    f\"~*OneCycleLr_UFTS ~*[{OneCycleLr_UFTS}]~*.\",\n",
    "    [\"cyan\", \"green\", \"cyan\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_optimizer_info(model)  # noqa: F405\n",
    "# warnings\n",
    "P_warning(\"[RES_Train -> True].\") if RES_Train else None  # noqa: F405\n",
    "P_warning(\"[TerminateOnHighTemp_M -> False] GPU temperature protection is OFF\") if not TerminateOnHighTemp_M else None  # noqa: F405\n",
    "print_Color(\"Setup Verbose END.\", [\"yellow\"])\n",
    "# MAIN LOOP\n",
    "try:\n",
    "    for epoch in range(1, max_epoch):\n",
    "        # Start Epoch\n",
    "        STG = \"Stage 1\" if epoch < Stage1_epoch else \"Stage 2\"\n",
    "        C_subset_epoch = subset_epoch if epoch < Stage1_epoch else subset_epoch_FT\n",
    "        if epoch > Stage1_epoch and load_SUB_BRW_LMODE_FN:\n",
    "            load_SUB_BRW_LMODE = 1\n",
    "        start_FULL_time = time.time()\n",
    "        if Auto_clear_cache:\n",
    "            subprocess.run([\"Cache_clear.cmd\"], shell=True)\n",
    "        # Reset TF_Summary_text_Dict\n",
    "        TF_Summary_text_Dict = {\"Model progress\": [], \"Error\": []}\n",
    "        # TSEC: Total-Subset-Epoch-Count\n",
    "        print_Color(\n",
    "            f\"\\n~*Epoch: ~*{epoch}~*/~*{max_epoch} (TSEC: {Total_SUB_epoch_C})~* | ~*[{STG}]\",\n",
    "            [\"normal\", \"cyan\", \"normal\", \"green\", \"blue\", \"green\"],\n",
    "            advanced_mode=True,\n",
    "        )\n",
    "        # warnings\n",
    "        P_warning(\"[TerminateOnHighTemp_M -> False] GPU temperature protection is OFF\") if not TerminateOnHighTemp_M else None  # noqa: F405\n",
    "        # DP\n",
    "        if not AdvSubsetC:\n",
    "            print_Color(\"Shuffling data...\", [\"yellow\"])\n",
    "            x_train, y_train = shuffle_data(x_train, y_train)\n",
    "        print_Color(\n",
    "            f\"~*Taking a subset of ~*[|{subset_size}|AdvSubset:{AdvSubsetC}]~*...\",\n",
    "            [\"yellow\", \"green\", \"yellow\"],\n",
    "            advanced_mode=True,\n",
    "        )\n",
    "        if AdvSubsetC:\n",
    "            if AdvSubsetC_SHR > 0 and epoch % AdvSubsetC_SHR == 0:\n",
    "                print_Color(\"└───Shuffling data...\", [\"yellow\"])\n",
    "                x_train, y_train = shuffle_data(x_train, y_train)\n",
    "                chosen_indices = []  # Reset chosen_indices\n",
    "\n",
    "            available_indices = list(set(range(x_train.shape[0])) - set(chosen_indices))\n",
    "\n",
    "            if len(available_indices) < subset_size:\n",
    "                # DEBUG\n",
    "                # print('[DEBUG]-[AdvSubset]: Not enough available indices using the indices that were chosen the longest time ago.')\n",
    "                # If there are not enough available indices, choose from the indices that were chosen the longest time ago\n",
    "                old_indices = chosen_indices[: subset_size - len(available_indices)]\n",
    "                subset_indices = old_indices + list(np.random.choice(available_indices, len(available_indices), replace=False))\n",
    "\n",
    "                # Update the list of chosen indices and their sizes\n",
    "                chosen_indices = chosen_indices[len(old_indices) :] + subset_indices\n",
    "                subset_sizes = subset_sizes[len(old_indices) :] + [subset_size] * len(subset_indices)\n",
    "            else:\n",
    "                subset_indices = list(np.random.choice(available_indices, subset_size, replace=False))\n",
    "\n",
    "                # Add the chosen indices to the list of already chosen indices\n",
    "                chosen_indices += subset_indices\n",
    "                subset_sizes += [subset_size] * len(subset_indices)\n",
    "        else:\n",
    "            subset_indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "        # Taking the subset\n",
    "        x_SUB_train = x_train[subset_indices]\n",
    "        y_SUB_train = y_train[subset_indices]\n",
    "        x_SUB_train, y_SUB_train = shuffle_data(x_SUB_train, y_SUB_train)\n",
    "        assert len(x_SUB_train) == subset_size, f\"Expected subset size of {subset_size}, but got {len(x_SUB_train)}\"\n",
    "        print_Color(\"Preparing train data...\", [\"yellow\"])\n",
    "        # if epoch == 1: # OLD\n",
    "        #     print_Color('- ImageDataGenerator fit...', ['yellow'])\n",
    "        #     train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=6)\n",
    "        #     print_Color('- ImageDataGenerator fit done.', ['yellow'])\n",
    "        if epoch == 1 or ALWAYS_REFIT_IDG == 2:\n",
    "            if os.path.exists(IDG_FitP_PATH) and not ALWAYS_REFIT_IDG:\n",
    "                print_Color(\"- Loading fitted ImageDataGenerator...\", [\"yellow\"])\n",
    "                train_SUB_datagen = pickle.load(open(IDG_FitP_PATH, \"rb\"))\n",
    "            else:\n",
    "                print_Color(\"- Fitting ImageDataGenerator...\", [\"yellow\"])\n",
    "                IDG_FIT_rc = 3 if ALWAYS_REFIT_IDG == 2 else 12\n",
    "                train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=2)\n",
    "                pickle.dump(train_SUB_datagen, open(IDG_FitP_PATH, \"wb\"))\n",
    "            print_Color(\"- ImageDataGenerator fit done.\", [\"yellow\"])\n",
    "\n",
    "        print_Color(\"- Augmenting Image Data...\", [\"yellow\"])\n",
    "        train_SUB_augmented_images = train_SUB_datagen.flow(\n",
    "            x_SUB_train * 255, y_SUB_train, shuffle=False, batch_size=len(x_SUB_train)\n",
    "        ).__next__()\n",
    "        print_Color(\"- Normalizing Image Data...\", [\"yellow\"])\n",
    "        x_SUB_train = normalize_TO_RANGE(train_SUB_augmented_images[0], 0, 255)\n",
    "        x_SUB_train = apply_clahe_rgb_array(x_SUB_train, 0.5) / 255\n",
    "        # x_SUB_train = x_SUB_train / 255\n",
    "        x_SUB_train = normalize_TO_RANGE(Z_SCORE_normalize(x_SUB_train), 0, 1)\n",
    "        y_SUB_train = train_SUB_augmented_images[1]\n",
    "        # DEBUG\n",
    "        if Debug_OUTPUT_DPS and (epoch % Debug_OUTPUT_DPS_freq == 0 or epoch == 1):\n",
    "            SITD = np.random.choice(subset_size, size=400, replace=False)\n",
    "            S_dir = \"Samples/TSR_SUB_400_\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "            print_Color(\n",
    "                f\"~*- Debug DP Sample dir: ~*{S_dir}\",\n",
    "                [\"red\", \"green\"],\n",
    "                advanced_mode=True,\n",
    "            )\n",
    "            save_images_to_dir(np.clip(x_SUB_train[SITD], 0, 1), y_SUB_train[SITD], S_dir)\n",
    "        with file_writer.as_default():\n",
    "            # For Pneumonia\n",
    "            indices = np.where(np.all(y_SUB_train[SITD] == (0, 1), axis=-1))\n",
    "            tensor = np.clip(x_SUB_train[SITD][indices], 0, 1)\n",
    "            tf.summary.image(\"Debug SUB_DP Samples (Pneumonia)\", tensor, step=epoch, max_outputs=4)\n",
    "            # For Normal\n",
    "            indices = np.where(np.all(y_SUB_train[SITD] == (1, 0), axis=-1))\n",
    "            tensor = np.clip(x_SUB_train[SITD][indices], 0, 1)\n",
    "            tf.summary.image(\"Debug SUB_DP Samples (Normal)\", tensor, step=epoch, max_outputs=4)\n",
    "            del indices, tensor\n",
    "        # learning_rate_schedule_SUB\n",
    "        if Stage1_epoch == 0:\n",
    "            CU_LR = MIN_LR\n",
    "        elif epoch >= Stage1_epoch and CU_LR > MIN_LR:\n",
    "            if (CU_LR - DEC_LR) < MIN_LR:\n",
    "                CU_LR = MIN_LR\n",
    "            else:\n",
    "                CU_LR -= DEC_LR\n",
    "        if (not OneCycleLr_UFTS) and Use_OneCycleLr:\n",
    "            learning_rate_schedule_SUB = OneCycleLr(\n",
    "                max_lr=CU_LR,\n",
    "                steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "                epochs=C_subset_epoch,\n",
    "            )\n",
    "        # FV\n",
    "        if Use_OneCycleLr:\n",
    "            print_Color(\n",
    "                f'~*Setting training OneCycleLr::maxlr to ~*[{(str(round(CU_LR, 8)) + \"~*~*\") if not OneCycleLr_UFTS else \"~*OneCycleLr_UFTS Is ON~*\"}]~*...',\n",
    "                [\"yellow\", \"green\", \"red\", \"green\", \"yellow\"],\n",
    "                advanced_mode=True,\n",
    "            )\n",
    "        print_Color(\n",
    "            f\"~*Setting training subset epoch.c to ~*[{C_subset_epoch}]~*...\",\n",
    "            [\"yellow\", \"green\", \"yellow\"],\n",
    "            advanced_mode=True,\n",
    "        )\n",
    "        # Train\n",
    "        print_Color(\"Training on subset...\", [\"green\"])\n",
    "        # Gen input callbacks\n",
    "        callbacks_dict = {\n",
    "            \"learning_rate_schedule_SUB\": learning_rate_schedule_SUB,\n",
    "            \"TerminateOnHighTemp_CB\": TerminateOnHighTemp_CB,\n",
    "            \"checkpoint_SUB\": checkpoint_SUB,\n",
    "            \"early_stopping\": early_stopping,\n",
    "            \"tensorboard_callback\": tensorboard_callback,\n",
    "            \"confusion_matrix_callback\": confusion_matrix_callback,\n",
    "            \"TerminateOnNaN_callback\": TerminateOnNaN_callback,\n",
    "            \"SwapEMAWeights_callback\": SwapEMAWeights_callback,\n",
    "        }\n",
    "        Active_callbacks = [callbacks_dict[cb] for cb, active in callbacks_active.items() if active]\n",
    "        start_SUBO_time = time.time()\n",
    "        try:\n",
    "            SUB_history = model.fit(\n",
    "                x_SUB_train,\n",
    "                y_SUB_train,\n",
    "                epochs=C_subset_epoch + Total_SUB_epoch_C,  # TO FIX TensorBoard (Total_SUB_epoch_C)\n",
    "                batch_size=Conf_batch_size_REV2,\n",
    "                validation_data=(x_test, y_test),\n",
    "                verbose=\"auto\",\n",
    "                initial_epoch=Total_SUB_epoch_C,  # TO FIX TensorBoard\n",
    "                callbacks=Active_callbacks,\n",
    "            )\n",
    "        except Exception as Err:\n",
    "            print_Color(f\"Error occurred during fitting: \\n{Err}\", [\"red\"])\n",
    "            TF_Summary_text_Dict[\"Error\"].append(f\"Error occurred during fitting: \\n{Err}\")\n",
    "            raise Exception(f\"Error occurred during fitting: \\n{Err}\")\n",
    "\n",
    "        end_SUBO_time = time.time()\n",
    "        print_Color(\"Subset training done.\", [\"green\"])\n",
    "        if load_SUB_BRW_LMODE == 1:\n",
    "            if max(SUB_history.history[\"val_accuracy\"]) > best_acc:\n",
    "                load_weights = True\n",
    "            elif min(SUB_history.history[\"val_loss\"]) < best_loss:\n",
    "                load_weights = True\n",
    "            else:\n",
    "                load_weights = False\n",
    "        else:\n",
    "            load_weights = True\n",
    "\n",
    "        if load_SUB_BRW and load_weights:\n",
    "            print_Color(\"Loading the best weights...\", [\"yellow\"])\n",
    "            # Get the filename of the best weights file\n",
    "            list_of_files = glob.glob(\"cache\\\\*.h5\")\n",
    "            try:\n",
    "                best_weights_filename = max(list_of_files, key=os.path.getctime)\n",
    "                print_Color(f\"Loading weights from file {best_weights_filename}...\", [\"yellow\"])\n",
    "                model.load_weights(best_weights_filename)\n",
    "            except Exception as Err:\n",
    "                print_Color(f\"ERROR: Failed to load weights. Error: {Err}\", [\"red\"])\n",
    "                TF_Summary_text_Dict[\"Error\"].append(f\"ERROR: Failed to load weights. Error: {Err}\")\n",
    "        elif load_SUB_BRW and (not load_weights):\n",
    "            print_Color_V2(\n",
    "                f'<light_red>Not loading weights<green>[<light_blue>BSR:<yellow>acc{{{max(SUB_history.history[\"val_accuracy\"]):.4f}}}, <yellow>loss{{{min(SUB_history.history[\"val_loss\"]):.4f}}}<light_magenta>|<light_blue>BTR:<green>acc{{{best_acc:.4f}}}, loss{{{best_loss:.4f}}}]'\n",
    "            )\n",
    "        all_histories.append(SUB_history.history)\n",
    "        checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "        # Evaluate the model on the test data\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "        # Extract the loss and accuracy from the evaluation results\n",
    "        loss = evaluation[0]\n",
    "        acc = evaluation[1]\n",
    "        print_Color(f\"~*Model Test acc: ~*{acc:.4f}\", [\"yellow\", \"green\"], advanced_mode=True)\n",
    "        print_Color(f\"~*Model Test loss: ~*{loss:.4f}\", [\"yellow\", \"green\"], advanced_mode=True)\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar(\"Model accuracy (Main-Sub_Re)\", acc, step=epoch)\n",
    "            tf.summary.scalar(\"Model loss (Main-Sub_Re)\", loss, step=epoch)\n",
    "        # If the accuracy is higher than the best_acc\n",
    "        if acc > best_acc:\n",
    "            print_Color_V2(f\"<green>Improved model accuracy from {best_acc:8f} to {acc:8f}. <light_cyan>Saving model.\")\n",
    "            TF_Summary_text_Dict[\"Model progress\"].append(f\"Improved model accuracy from `{best_acc:10f}` to `{acc:10f}` Saving model.\")\n",
    "            # Update the best_acc\n",
    "            best_acc = acc\n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == \"TF\":\n",
    "                    print_Color_V2(\"<cyan>Saving full model tf format...\")\n",
    "                    model.save(BEST_RSN, save_format=\"tf\")\n",
    "                else:\n",
    "                    print_Color_V2(\"<cyan>Saving full model H5 format...\")\n",
    "                    model.save(f\"{BEST_RSN}.h5\")\n",
    "            model.save_weights(\"PAI_model_weights.weights.h5\")\n",
    "        else:\n",
    "            print_Color_V2(f\"<light_red>Model accuracy did not improve from {best_acc:.10f}. Not saving model.\")\n",
    "\n",
    "        # If the loss is higher than the best_loss\n",
    "        if loss < best_loss:\n",
    "            print_Color_V2(f\"<green>Improved model loss from {best_loss:.8f} to {loss:.8f}. <light_cyan>Saving model.\")\n",
    "            TF_Summary_text_Dict[\"Model progress\"].append(f\"Improved model loss from `{best_loss:10f}` to `{loss:10f}` Saving model.\")\n",
    "            # Update the best_acc\n",
    "            best_loss = loss\n",
    "\n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == \"TF\":\n",
    "                    print_Color_V2(\"<cyan>Saving full model tf format...\")\n",
    "                    model.save(BEST_RSN + \"_BL\", save_format=\"tf\")\n",
    "                else:\n",
    "                    print_Color_V2(\"<cyan>Saving full model H5 format...\")\n",
    "                    model.save(f\"{BEST_RSN}_BL.h5\")\n",
    "            model.save_weights(\"PAI_model_weights_BL.weights.h5\")\n",
    "        else:\n",
    "            print_Color_V2(f\"<light_red>Model loss did not improve from {best_loss:.10f}. Not saving model.\")\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "        GPU_memUsage()  # noqa: F405\n",
    "        # Update TF summary text\n",
    "        for Key in TF_Summary_text_Dict:\n",
    "            TF_Summary_text_cache = f\"# @[{Key}].Data:\\n\"\n",
    "            if TF_Summary_text_Dict[Key] != []:\n",
    "                for ID, Item in enumerate(TF_Summary_text_Dict[Key]):\n",
    "                    TF_Summary_text_cache += f\"### Data |id: {str(ID)}| --> \\n#### ~ {Item}\\n\"\n",
    "                # tf.summary.text\n",
    "                with file_writer.as_default():\n",
    "                    tf.summary.text(Key, TF_Summary_text_cache, step=epoch)\n",
    "        # Epoch end\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_FULL_time\n",
    "        print_Color_V2(f\"<yellow>Time taken for epoch(FULL): <green>{epoch_time:.2f} <cyan>sec\")\n",
    "        epoch_SUB_time = end_SUBO_time - start_SUBO_time\n",
    "        print_Color_V2(f\"<yellow>Time taken for epoch(SUBo): <green>{epoch_SUB_time:.2f} <cyan>sec\")\n",
    "        epoch_OTHERO_time = epoch_time - epoch_SUB_time\n",
    "        print_Color_V2(f\"<yellow>Time taken for epoch(OTHERo): <green>{epoch_OTHERO_time:.2f} <cyan>sec\")\n",
    "        print_Color(\n",
    "            f\"<---------------------------------------|Epoch [{epoch}] END|--------------------------------------->\",\n",
    "            [\"cyan\"],\n",
    "        )\n",
    "        Total_SUB_epoch_C += C_subset_epoch  # TO FIX TensorBoard\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nKeyboardInterrupt. (Training stopped)\")\n",
    "except Exception as Err:\n",
    "    print(f\"Error while training model (Training stopped):\\n{Err}\")\n",
    "# End\n",
    "# Update TF summary text\n",
    "for Key in TF_Summary_text_Dict:\n",
    "    TF_Summary_text_cache = f\"# @[{Key}].Data:\\n\"\n",
    "    if TF_Summary_text_Dict[Key] != []:\n",
    "        for ID, Item in enumerate(TF_Summary_text_Dict[Key]):\n",
    "            TF_Summary_text_cache += f\"### Data |id: {str(ID)}| --> \\n#### ~ {Item}\\n\"\n",
    "        # tf.summary.text\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.text(Key, TF_Summary_text_cache, step=epoch)\n",
    "try:\n",
    "    history = {}\n",
    "    for key in all_histories[0].keys():\n",
    "        # For each metric, concatenate the values from all histories\n",
    "        history[key] = np.concatenate([h[key] for h in all_histories])\n",
    "except Exception as Err:\n",
    "    print(f\"Failed to make model `history` var.\\nERROR: {Err}\")\n",
    "else:\n",
    "    # Save history\n",
    "    save_list(history, f\"history\\\\Archive\\\\model_{EXPR_name}_history.pkl.gz\", compress=True)  # noqa: F405\n",
    "print(\"Training done.\\n\")\n",
    "# del vars\n",
    "try:\n",
    "    del train_SUB_datagen\n",
    "    del train_SUB_augmented_images\n",
    "    del x_SUB_train\n",
    "    del y_SUB_train\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev1 (⚠️deprecated⚠️)\n",
    "```\n",
    "Working: ✅\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " - Can cause overfitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "keras.backend.clear_session()\n",
    "# CONF\n",
    "Conf_batch_size = 8\n",
    "OneCycleLr_epoch = 20\n",
    "Learning_rate_conf = 3  # 1 and 2 for custom learning_rate_fn and 3 for OneCycleLr (Better for full training)\n",
    "# TensorBoard conf\n",
    "TensorBoard_UF = 1  # 1 for Slow 2 for fast (very slow tarining)\n",
    "# Learning rate configuration\n",
    "Learning_rate_conf_SET2C = 3  # 1 for SGD and 2 for Adam and... for lower lr 3 for very high lr\n",
    "MAX_LR = 0.0174\n",
    "# First time\n",
    "if Learning_rate_conf == 1:\n",
    "    learning_rate_start = 8e-04\n",
    "    learning_rate_max = 5e-03\n",
    "    learning_rate_min = 5e-05\n",
    "    learning_rate_rampup_epochs = 5\n",
    "    learning_rate_sustain_epochs = 1\n",
    "    learning_rate_exp_decay = 0.3\n",
    "    # TEMP\n",
    "    # learning_rate_start = 8e-04\n",
    "    # learning_rate_max = 1e-02\n",
    "    # learning_rate_min = 8e-04\n",
    "    # learning_rate_rampup_epochs = 5\n",
    "    # learning_rate_sustain_epochs = 3\n",
    "    # learning_rate_exp_decay = .45\n",
    "# 2th time\n",
    "if Learning_rate_conf == 2:\n",
    "    if Learning_rate_conf_SET2C == 1:\n",
    "        learning_rate_start = 4.10e-06\n",
    "        learning_rate_max = 4.10e-06\n",
    "        learning_rate_min = 4.10e-06\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "\n",
    "    elif Learning_rate_conf_SET2C == 2:\n",
    "        learning_rate_start = 4e-07\n",
    "        learning_rate_max = 4e-07\n",
    "        learning_rate_min = 4e-07\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "\n",
    "    elif Learning_rate_conf_SET2C == 3:\n",
    "        learning_rate_start = 5e-04\n",
    "        learning_rate_max = 5e-04\n",
    "        learning_rate_min = 5e-04\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "# Function to build learning rate schedule\n",
    "if Learning_rate_conf in [1, 2]:\n",
    "\n",
    "    def build_learning_rate_fn(\n",
    "        lr_start=learning_rate_start,\n",
    "        lr_max=learning_rate_max,\n",
    "        lr_min=learning_rate_min,\n",
    "        lr_rampup_epochs=learning_rate_rampup_epochs,\n",
    "        lr_sustain_epochs=learning_rate_sustain_epochs,\n",
    "        lr_exp_decay=learning_rate_exp_decay,\n",
    "    ):\n",
    "        lr_max = lr_max * tf.distribute.get_strategy().num_replicas_in_sync\n",
    "\n",
    "        def learning_rate_fn(epoch):\n",
    "            if epoch < lr_rampup_epochs:\n",
    "                lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "            elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "                lr = lr_max\n",
    "            else:\n",
    "                lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "            return lr\n",
    "\n",
    "        return learning_rate_fn\n",
    "\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch_train = len(x_train) // Conf_batch_size\n",
    "\n",
    "\n",
    "# Set up callbacks\n",
    "class EpochEndMON(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        if hasattr(optimizer, \"lr\"):\n",
    "            lr = tf.keras.backend.get_value(optimizer.lr)\n",
    "            print(f\"\\nLearning rate for epoch {epoch + 1} is {lr}\")\n",
    "        if hasattr(optimizer, \"momentum\"):\n",
    "            momentum = tf.keras.backend.get_value(optimizer.momentum)\n",
    "            print(f\"Momentum for epoch {epoch + 1} is {momentum}\")\n",
    "        if logs:\n",
    "            val_loss = logs.get(\"val_loss\")\n",
    "            val_acc = logs.get(\"val_accuracy\")\n",
    "            print(f\"Validation loss for epoch {epoch + 1} is {val_loss}\")\n",
    "            print(f\"Validation accuracy for epoch {epoch + 1} is {val_acc}\")\n",
    "\n",
    "        print_Color_V2(\n",
    "            f\"`red`<!--------------------------------------|Epoch`yellow` [{epoch + 1}]`red` End|--------------------------------------!> `green`PBE↓\",\n",
    "            start_char=\"`\",\n",
    "            end_char=\"`\",\n",
    "        )\n",
    "\n",
    "\n",
    "# Instantiate the callback\n",
    "EpochEndMON_callback = EpochEndMON()\n",
    "if Learning_rate_conf in [1, 2]:\n",
    "    learning_rate_fn = build_learning_rate_fn()\n",
    "    learning_rate_schedule = LearningRateScheduler(learning_rate_fn, verbose=1)\n",
    "else:\n",
    "    learning_rate_schedule = OneCycleLr(max_lr=MAX_LR, steps_per_epoch=steps_per_epoch_train, epochs=OneCycleLr_epoch)\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    checkpoint_BVAC = ModelCheckpoint(\n",
    "        \"models\\\\Temp\\\\bestVAC_model\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "    checkpoint_BVL = ModelCheckpoint(\n",
    "        \"models\\\\Temp\\\\bestVL_model\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "else:\n",
    "    checkpoint_BVAC = ModelCheckpoint(\n",
    "        \"models\\\\Temp\\\\bestVAC_model.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "    checkpoint_BVL = ModelCheckpoint(\n",
    "        \"models\\\\Temp\\\\bestVL_model.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=2, verbose=1, restore_best_weights=True)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "TensorBoard_update_freq = \"batch\" if TensorBoard_UF == 2 else \"epoch\"\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    write_images=True,\n",
    "    histogram_freq=1,\n",
    "    update_freq=TensorBoard_update_freq,\n",
    "    write_grads=True,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Log dir:\", log_dir)\n",
    "# MInfo\n",
    "print(\"Input Shape:\", model.input_shape)\n",
    "print(\"Output Shape:\", model.output_shape)\n",
    "print(\"Loss Function:\", model.loss)\n",
    "print(\"Training the model...\\n\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=256,\n",
    "    batch_size=Conf_batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=\"auto\",\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        tensorboard_callback,\n",
    "        learning_rate_schedule,\n",
    "        checkpoint_BVAC,\n",
    "        checkpoint_BVL,\n",
    "        EpochEndMON_callback,\n",
    "    ],\n",
    ")\n",
    "print(\"Training done.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "Extra_EXT = \"_T\"\n",
    "# Save the weights\n",
    "print(\"Saving weights...\")\n",
    "model.save_weights(\"PAI_model_weights.h5\")\n",
    "print(\"Saving full model...\")\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    print(\"Saving full model tf format...\")\n",
    "    model.save(f\"PAI_model{Extra_EXT}\", save_format=\"tf\")\n",
    "else:\n",
    "    try:\n",
    "        model.save(f\"PAI_model{Extra_EXT}.h5\")\n",
    "    except ValueError:\n",
    "        print(\"failed to save in .h5 format!\")\n",
    "        print(\"Saving full model in tf format...\")\n",
    "        model.save(f\"PAI_model{Extra_EXT}\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection (memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release all the GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "GPU_memUsage()  # noqa: F405\n",
    "print(\"Realising all memory...\")\n",
    "device.reset()\n",
    "GPU_memUsage()  # noqa: F405\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "save_list(history, \"history\\\\model_history.pkl.gz\", compress=True)  # noqa: F405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history\n",
    "history = load_list(\"history\\\\model_history.pkl.gz\", compressed=True)  # noqa: F405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:52.565658900Z",
     "start_time": "2023-12-28T07:04:51.032425100Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chunk size for 3D plot\n",
    "chunk_size = 6  # Change this to your desired chunk size\n",
    "\n",
    "\n",
    "def convert_history(history):\n",
    "    if isinstance(history, tf.keras.callbacks.History):\n",
    "        return history.history\n",
    "    else:\n",
    "        return history\n",
    "\n",
    "\n",
    "def chunked_data(data, chunk_size):\n",
    "    return [data[i : i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "\n",
    "try:\n",
    "    EPM = \"Epoch(Subset)\" if not isinstance(history, tf.keras.callbacks.History) else \"Epoch\"\n",
    "    history = convert_history(history)\n",
    "\n",
    "    # Calculate deltas\n",
    "    delta_loss = np.diff(history[\"loss\"])\n",
    "    delta_accuracy = np.diff(history[\"accuracy\"])\n",
    "\n",
    "    try:\n",
    "        delta_val_loss = np.diff(history[\"val_loss\"])\n",
    "        delta_val_accuracy = np.diff(history[\"val_accuracy\"])\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_loss or val_accuracy for delta calculation.\")\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    # Loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    try:\n",
    "        plt.plot(history[\"val_loss\"], label=\"val_loss\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_loss.\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(EPM)\n",
    "    plt.ylim(top=max(history[\"val_loss\"][10:]), bottom=0)  # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Density plot for loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(history[\"loss\"], label=\"loss density\", color=\"blue\", alpha=0.5, bins=100)\n",
    "    try:\n",
    "        plt.hist(\n",
    "            history[\"val_loss\"],\n",
    "            label=\"val_loss density\",\n",
    "            color=\"orange\",\n",
    "            alpha=0.5,\n",
    "            bins=100,\n",
    "        )\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_loss (density plot).\")\n",
    "    plt.title(\"Density Plot for Loss\")\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.xlim(right=max(history[\"val_loss\"][10:]), left=0)  # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history[\"accuracy\"], label=\"accuracy\")\n",
    "    try:\n",
    "        plt.plot(history[\"val_accuracy\"], label=\"val_accuracy\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_accuracy.\")\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Density plot for accuracy\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(history[\"accuracy\"], label=\"accuracy density\", color=\"blue\", alpha=0.5, bins=40)\n",
    "    try:\n",
    "        plt.hist(\n",
    "            history[\"val_accuracy\"],\n",
    "            label=\"val_accuracy density\",\n",
    "            color=\"orange\",\n",
    "            alpha=0.5,\n",
    "            bins=40,\n",
    "        )\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_accuracy (density plot).\")\n",
    "    plt.title(\"Density Plot for Accuracy\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Delta Loss\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(delta_loss, label=\"delta_loss\")\n",
    "    try:\n",
    "        plt.plot(delta_val_loss, label=\"delta_val_loss\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load delta_val_loss.\")\n",
    "    plt.title(\"Delta Model Loss\")\n",
    "    plt.ylabel(\"Delta Loss\")\n",
    "    plt.ylim(top=1.5, bottom=-1.5)\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    # Delta Accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(delta_accuracy, label=\"delta_accuracy\")\n",
    "    try:\n",
    "        plt.plot(delta_val_accuracy, label=\"delta_val_accuracy\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load delta_val_accuracy.\")\n",
    "    plt.title(\"Delta Model Accuracy\")\n",
    "    plt.ylabel(\"Delta Accuracy\")\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Calculate chunked data\n",
    "    chunked_loss = chunked_data(history[\"val_loss\"], chunk_size)\n",
    "    chunked_accuracy = chunked_data(history[\"val_accuracy\"], chunk_size)\n",
    "\n",
    "    # Clip the loss values to a maximum of max(history['val_loss'][10:])\n",
    "    max_loss = max(history[\"val_loss\"][10:])\n",
    "    chunked_loss = np.clip(chunked_loss, a_min=None, a_max=max_loss)\n",
    "\n",
    "    # Create 3D surface plots for each chunk\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax = fig.add_subplot(121, projection=\"3d\")\n",
    "    X = np.arange(len(chunked_loss))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_loss).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap=\"viridis\")\n",
    "    ax.set_title(\"3D Surface Plot of Chunked Loss\")\n",
    "    ax.set_xlabel(\"Chunk Index\")\n",
    "    ax.set_ylabel(\"Epoch\")\n",
    "    ax.set_zlabel(\"Loss\")\n",
    "\n",
    "    ax = fig.add_subplot(122, projection=\"3d\")\n",
    "    X = np.arange(len(chunked_accuracy))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_accuracy).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap=\"viridis\")\n",
    "    ax.set_title(\"3D Surface Plot of Chunked Accuracy\")\n",
    "    ax.set_xlabel(\"Chunk Index\")\n",
    "    ax.set_ylabel(\"Epoch\")\n",
    "    ax.set_zlabel(\"Accuracy\")\n",
    "\n",
    "    # Function to calculate the average of chunks\n",
    "    def chunked_average(values, chunk_size):\n",
    "        return [np.mean(values[i : i + chunk_size]) for i in range(0, len(values), chunk_size)]\n",
    "\n",
    "    avg_accuracy_chunks = chunked_average(history[\"val_accuracy\"], chunk_size)\n",
    "    avg_loss_chunks = chunked_average(history[\"val_loss\"], chunk_size)\n",
    "\n",
    "    # Find the chunk with the highest average accuracy\n",
    "    Acc_max_acc_chunk_index = np.argmax(avg_accuracy_chunks)\n",
    "    max_acc_value = avg_accuracy_chunks[Acc_max_acc_chunk_index]\n",
    "\n",
    "    # Find the chunk with the lowest average loss\n",
    "    Loss_max_acc_chunk_index = np.argmin(avg_loss_chunks)\n",
    "    min_loss_value = avg_loss_chunks[Loss_max_acc_chunk_index]\n",
    "\n",
    "    # Create a pile plot for accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(avg_accuracy_chunks)), avg_accuracy_chunks, label=\"Average Accuracy\")\n",
    "    plt.bar(\n",
    "        Acc_max_acc_chunk_index,\n",
    "        max_acc_value,\n",
    "        color=\"red\",\n",
    "        label=\"Highest Average Accuracy\",\n",
    "    )\n",
    "    plt.xlabel(\"Chunk\")\n",
    "    plt.ylabel(\"Average Accuracy\")\n",
    "    plt.title(\"Average Validation Accuracy per Chunk\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Create a pile plot for loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(\n",
    "        range(len(avg_loss_chunks)),\n",
    "        avg_loss_chunks,\n",
    "        color=\"green\",\n",
    "        label=\"Average Loss\",\n",
    "    )\n",
    "    plt.bar(\n",
    "        Loss_max_acc_chunk_index,\n",
    "        min_loss_value,\n",
    "        color=\"red\",\n",
    "        label=\"Lowest Average Loss\",\n",
    "    )\n",
    "    plt.xlabel(\"Chunk\")\n",
    "    plt.ylabel(\"Average Loss\")\n",
    "    plt.title(\"Average Validation Loss per Chunk\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Function to calculate the average of each epoch across chunks, ignoring the first chunk\n",
    "    def average_across_chunks(values, chunk_size):\n",
    "        num_chunks = len(values) // chunk_size\n",
    "        avg_values = []\n",
    "        for epoch in range(chunk_size):\n",
    "            epoch_values = [values[chunk * chunk_size + epoch] for chunk in range(1, num_chunks)]\n",
    "            avg_values.append(np.mean(epoch_values))\n",
    "        return avg_values\n",
    "\n",
    "    # Calculate the average accuracy and loss for each epoch across chunks, ignoring the first chunk\n",
    "    avg_accuracy_epochs = average_across_chunks(history[\"val_accuracy\"], chunk_size)\n",
    "    avg_loss_epochs = average_across_chunks(history[\"val_loss\"], chunk_size)\n",
    "\n",
    "    # Create a bar plot for average accuracy and loss of each epoch across chunks\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create an index for each epoch\n",
    "    epoch_indices = np.arange(len(avg_accuracy_epochs))\n",
    "\n",
    "    bars1 = plt.bar(\n",
    "        epoch_indices - 0.2,\n",
    "        avg_accuracy_epochs,\n",
    "        width=0.4,\n",
    "        label=\"Average Accuracy\",\n",
    "        color=\"blue\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    bars2 = plt.bar(\n",
    "        epoch_indices + 0.2,\n",
    "        avg_loss_epochs,\n",
    "        width=0.4,\n",
    "        label=\"Average Loss\",\n",
    "        color=\"orange\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Epoch (within chunk)\")\n",
    "    plt.ylabel(\"Average Value\")\n",
    "    plt.title(\"Average Validation Accuracy and Loss for Each Epoch Across Chunks (Ignoring First Chunk)\")\n",
    "    plt.xticks(epoch_indices, [f\"Epoch {i + 1}\" for i in epoch_indices])  # Set x-tick labels to epoch numbers\n",
    "\n",
    "    # Adding the numbers on the bars\n",
    "    for bar in bars1:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 5.0, yval, round(yval, 4), va=\"bottom\")  # va: vertical alignment\n",
    "\n",
    "    for bar in bars2:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 5.0, yval, round(yval, 4), va=\"bottom\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except (ValueError, NameError) as E:\n",
    "    print(f\"\\033[91mFailed to load model history.\\nError: {E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Predicting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "\n",
    "Extra_EXT = \"_T\"  # _T or _T_BL\n",
    "Train_data_test = False\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f\"PAI_model{Extra_EXT}\")\n",
    "else:\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f\"PAI_model{Extra_EXT}.h5\")\n",
    "\n",
    "# Ensure the model's input_shape matches your data\n",
    "assert model.input_shape[1:] == (\n",
    "    img_res[0],\n",
    "    img_res[1],\n",
    "    img_res[2],\n",
    "), \"Models input shape doesnt match data.\"\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = model.predict(x_val)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Print acc\n",
    "print(\"Val data acc:\")\n",
    "evaluate_model_full(y_val, val_predictions)  # noqa: F405\n",
    "print(\"Test data acc:\")\n",
    "evaluate_model_full(y_test, test_predictions)  # noqa: F405\n",
    "\n",
    "# format data\n",
    "val_predictions = np.argmax(val_predictions, axis=1)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "y_val_original = np.argmax(y_val, axis=1)\n",
    "y_test_original = np.argmax(y_test, axis=1)\n",
    "# Visualize the predictions on validation data as a grid of squares\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_val[i])\n",
    "    plt.title(f\"True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = x_val[i]\n",
    "    heatmap = make_gradcam_heatmap(\n",
    "        img[np.newaxis, ...],\n",
    "        model,\n",
    "        \"top_activation\",\n",
    "        second_last_conv_layer_name=\"top_conv\",\n",
    "        sensitivity_map=1,\n",
    "    )\n",
    "    heatmap = cv2.resize(np.clip(heatmap, 0, 1), (img.shape[0], img.shape[1]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    if RANGE_NOM:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + (img * 0.6)\n",
    "    else:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + ((img / 255) * 0.6)\n",
    "    # clip\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # ensure the values are in the range [0, 1]\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f\"True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the list of labels\n",
    "labels = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "\n",
    "# Create a confusion matrix for validation data\n",
    "val_cm = confusion_matrix(y_val_original, val_predictions)\n",
    "\n",
    "# Create a confusion matrix for test data\n",
    "test_cm = confusion_matrix(y_test_original, test_predictions)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for validation data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(val_cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix - Validation Data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(test_cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix - Test Data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Define the range of test data sizes to use\n",
    "data_sizes = range(1, len(x_test), 4)\n",
    "\n",
    "# Create a list to store the number of incorrect predictions for each test data size\n",
    "incorrect_predictions = []\n",
    "\n",
    "# Generate predictions and track incorrect predictions for each data size\n",
    "for size in tqdm(data_sizes, desc=\"Predicting\", unit=\"dpb\"):\n",
    "    if traceback.format_exc() == \"\":\n",
    "        break\n",
    "    # Garbage Collection (memory)\n",
    "    gc.collect()\n",
    "    # Randomly select a subset of test data\n",
    "    indices = np.random.choice(len(x_test), size, replace=False)\n",
    "    x_test_subset = x_test[indices]\n",
    "    y_test_subset = y_test[indices]\n",
    "\n",
    "    # Make predictions on the subset of test data\n",
    "    test_predictions = model.predict(\n",
    "        x_test_subset,\n",
    "        batch_size=1,\n",
    "        verbose=0,\n",
    "        max_queue_size=120,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False,\n",
    "    )\n",
    "    test_predictions = np.argmax(test_predictions, axis=1)\n",
    "    y_test_original_subset = np.argmax(y_test_subset, axis=1)\n",
    "\n",
    "    # Calculate the number of incorrect predictions\n",
    "    incorrect_preds = np.sum(test_predictions != y_test_original_subset)\n",
    "    incorrect_predictions.append(incorrect_preds)\n",
    "\n",
    "try:\n",
    "    # Plot the number of incorrect predictions vs. the number of data points\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data_sizes, incorrect_predictions)\n",
    "    plt.xlabel(\"Number of Data Points\")\n",
    "    plt.ylabel(\"Number of Incorrect Predictions\")\n",
    "    # Add gridlines for the x and y axes\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Change the tick spacing for the x and y axes\n",
    "    plt.xticks(np.arange(min(data_sizes), max(data_sizes) + 1, 50))\n",
    "    plt.yticks(np.arange(0, max(incorrect_predictions) + 5, 3))\n",
    "\n",
    "    plt.title(\"Number of Incorrect Predictions vs. Number of Data Points\")\n",
    "    plt.show()\n",
    "except Exception:\n",
    "    P_warning(\"Failed to plot incorrect predictions vs. data points\")  # noqa: F405"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
