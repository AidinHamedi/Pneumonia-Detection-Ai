#scale_data
def scale_data_NP(data):
    if scale_data_NP_M:
        data = data.astype('float32')
        data = (data - 127.5) / 127.5
        return data
    else:
        return data / 255
#add_image_grain
def add_image_grain(image, intensity = 0.01):
    # Generate random noise array
    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)

    # Scale the noise array
    scaled_noise = (noise * intensity).astype(np.float32)
    # Add the noise to the image
    noisy_image = cv2.add(image, scaled_noise)

    return noisy_image
#adjust_brightness
# V1
def adjust_brightness(images, target_average):
    # Calculate the average pixel value of all the images
    overall_average = np.mean(images)

    # Iterate over each image in the array
    for i in range(len(images)):
        # Calculate the average pixel value of the current image
        image_average = np.mean(images[i])

        # Compare the image average with the overall average
        if image_average > overall_average + 10:
            # Increase brightness by adding a constant value
            images[i] = np.clip(images[i] - random.randint(6, 25), 0, 255)
        elif image_average < overall_average - 10:
            # Decrease brightness by subtracting a constant value
            images[i] = np.clip(images[i] + random.randint(6, 25), 0, 255)

    return images
# V2 (Very slow NOT Recommended)
# def adjust_brightness(images, target_average):
#     # Calculate the average pixel value of all the images
#     overall_average = np.mean(images)

#     # Initialize a variable to keep track of the number of deleted images
#     deleted_images = 0

#     # Create a progress bar
#     pbar = tqdm(total=len(images), desc='Processing images')

#     # Iterate over each image in the array
#     for i in range(len(images)):
#         # Adjust the index to account for deleted images
#         adjusted_index = i - deleted_images

#         # Calculate the average pixel value of the current image
#         image_average = np.mean(images[adjusted_index])

#         # Compare the image average with the overall average
#         if image_average > overall_average + 50 or image_average < overall_average - 60:
#             # If the image brightness is 45 units higher than the overall average, delete the image
#             images = np.delete(images, adjusted_index, axis=0)
#             # Increment the count of deleted images
#             deleted_images += 1
#         elif image_average > overall_average + 10:
#             # Increase brightness by adding a random value between 6 and 25
#             images[adjusted_index] = np.clip(images[adjusted_index] - random.randint(6, 25), 0, 255)
#         elif image_average < overall_average - 10:
#             # Decrease brightness by subtracting a random value between 6 and 25
#             images[adjusted_index] = np.clip(images[adjusted_index] + random.randint(6, 25), 0, 255)

#         # Update the progress bar
#         pbar.update(1)

#     # Close the progress bar
#     pbar.close()

#     print(f'deleted_images: {deleted_images}')
#     return images
#apply_clahe_rgb_array
def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):
    # Create a CLAHE object
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    
    # Iterate over each image in the array
    for i in range(len(images)):
        # Split the image into color channels
        b, g, r = cv2.split(images[i])
        
        # Convert the channels to the appropriate format
        b = cv2.convertScaleAbs(b)
        g = cv2.convertScaleAbs(g)
        r = cv2.convertScaleAbs(r)
        
        # Apply adaptive histogram equalization to each channel
        equalized_b = clahe.apply(b)
        equalized_g = clahe.apply(g)
        equalized_r = clahe.apply(r)

        # Merge the equalized channels back into an image
        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))

        # Replace the original image with the equalized image in the array
        images[i] = equalized_image

    return images
#noise_func
def noise_func(image):
    noise_type = np.random.choice(['L1', 'L2', 'L3', 'none'])
    new_image = np.copy(image)
    
    if noise_type == 'L3':
        intensityL2 = random.uniform(-0.05, 0.05)
        intensityL1 = random.uniform(-0.04, 0.04)
    else:
        intensityL2 = random.uniform(-0.07, 0.07)
        intensityL1 = random.uniform(-0.05, 0.05)
    
    block_size_L1 = random.randint(16, 32)
    block_size_L2 = random.randint(32, 64)
    
    if noise_type == 'L2' or noise_type == 'L3':
        for i in range(0, image.shape[0], block_size_L2):
            for j in range(0, image.shape[1], block_size_L2):
                block = image[i:i+block_size_L2, j:j+block_size_L2]
                block = (np.random.rand() * intensityL2 + 1) * block
                new_image[i:i+block_size_L2, j:j+block_size_L2] = block
        image = new_image      
        
    if noise_type == 'L1' or noise_type == 'L3': 
        for i in range(0, image.shape[0], block_size_L1):
            for j in range(0, image.shape[1], block_size_L1):
                block = image[i:i+block_size_L1, j:j+block_size_L1]
                block = (np.random.rand() * intensityL1 + 1) * block
                new_image[i:i+block_size_L1, j:j+block_size_L1] = block
    
    if add_img_grain:
        intensity = random.uniform(0, 0.035)  # Random intensity between 0 and 0.026
        new_image = add_image_grain(new_image, intensity=intensity)
    return new_image
#shuffle_data
def shuffle_data(x, y):
    indices = np.arange(x.shape[0])
    np.random.shuffle(indices)
    x = x[indices]
    y = y[indices]
    return x, y
#save_images_to_dir
def save_images_to_dir(images, labels, dir_path):
    # create the directory if it doesn't exist
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    # iterate over the images and labels
    for i, (image, label) in enumerate(zip(images, labels)):
        # get the class label
        class_label = np.argmax(label)
        # create the file path
        file_path = os.path.join(dir_path, f'image_{i}_class_{class_label}.png')
        # save the image to the file path
        plt.imsave(file_path, image.squeeze())
    # compress the directory
    shutil.make_archive(dir_path, 'gztar', dir_path)
    # remove the original directory
    shutil.rmtree(dir_path)
# Create an ImageDataGenerator for the training set
if OP_HDC:
    print_Color('Using OP_HDC IDG...', ['yellow'])
    train_datagen = ImageDataGenerator(
        horizontal_flip=True,
        vertical_flip=True,
        rotation_range=179,
        zoom_range=0.24, 
        shear_range=0.22,
        width_shift_range=0.21,
        brightness_range=(0.86, 1.13),
        height_shift_range=0.21,
        channel_shift_range=100,
        featurewise_center=False,
        featurewise_std_normalization=False,
        interpolation_order=interpolation_order_IFG,
        fill_mode='nearest', # constant
        preprocessing_function=noise_func
    )
else:
    print_Color('Using Def IDG...', ['yellow'])
    train_datagen = ImageDataGenerator(
        horizontal_flip=True,
        vertical_flip=True,
        rotation_range=179,
        zoom_range=0.26, 
        shear_range=0.25,
        width_shift_range=0.25,
        brightness_range=(0.8, 1.15),
        height_shift_range=0.25,
        channel_shift_range=100,
        featurewise_center=False,
        interpolation_order=interpolation_order_IFG,
        featurewise_std_normalization=False,
        fill_mode='nearest', # constant
        preprocessing_function=noise_func
    )
train_datagen_SM = ImageDataGenerator(
    horizontal_flip=False,
    vertical_flip=False,
    rotation_range=20,
    zoom_range=0.07, 
    shear_range=0.07,
    width_shift_range=0.07,
    brightness_range=(0.99, 1.01),
    height_shift_range=0.07,
    channel_shift_range=0,
    featurewise_center=False,
    interpolation_order=interpolation_order_IFG,
    featurewise_std_normalization=False
)
# Create an iterator for the training set
train_generator_SM = train_datagen_SM.flow_from_directory(
    train_dir,
    target_size=(img_res[0], img_res[1]),
    batch_size=sum([len(files) for r, d, files in os.walk(train_dir)]),
    class_mode='binary')
# Create an ImageDataGenerator for the validation set (OP)
if Make_EV_DATA:
    val_datagen = ImageDataGenerator(
        horizontal_flip=False,
        zoom_range = 0.01, 
        width_shift_range=0.01, 
        interpolation_order=interpolation_order_IFG,
        height_shift_range=0.01)

    # Create an iterator for the validation set
    val_generator = val_datagen.flow_from_directory(
        validation_dir,
        target_size=(img_res[0], img_res[1]),
        batch_size=sum([len(files) for r, d, files in os.walk(validation_dir)]),
        class_mode='binary',
        color_mode='rgb')

    # Create an ImageDataGenerator for the test set
    test_datagen = ImageDataGenerator(
        horizontal_flip=False,
        zoom_range = 0.01, 
        width_shift_range=0.01, 
        interpolation_order=interpolation_order_IFG,
        height_shift_range=0.01)

    # Create an iterator for the test set
    test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(img_res[0], img_res[1]),
        batch_size=sum([len(files) for r, d, files in os.walk(test_dir)]),
        class_mode='binary',
        color_mode='rgb')
# Load all images and labels into memory
print_Color('Loading all images and labels into memory...', ['yellow'])
x_train, y_train = next(iter(train_generator_SM))
if Make_EV_DATA:
    x_val, y_val = next(iter(val_generator))
    x_test, y_test = next(iter(test_generator))
# fit parameters from data
# train_datagen.fit(x_train)
#to_categorical (TEMP)
if categorical_IMP:
    print_Color('Making categorical data...', ['yellow'])
    y_train = to_categorical(y_train, num_classes=2)
    if Make_EV_DATA:
        y_val = to_categorical(y_val, num_classes=2)
        y_test = to_categorical(y_test, num_classes=2)
# Use_SMOTE
if Use_SMOTE:
    print_Color('SMOTE...', ['yellow'])
    # Convert y_train from one-hot encoding to label encoding
    y_train_label_encoded = np.argmax(y_train, axis=1)

    # Print the original label distribution
    unique, counts = np.unique(y_train_label_encoded, return_counts=True)
    print_Color(f'~*- Original label distribution: ~*{dict(zip(unique, counts))}', ['normal', 'blue'], advanced_mode=True)

    # Use SMOTE to oversample the minority class
    smote = SMOTE(random_state=42)
    x_train_res, y_train_res_label_encoded = smote.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train_label_encoded)

    # Print the resampled label distribution
    unique_res, counts_res = np.unique(y_train_res_label_encoded, return_counts=True)
    print_Color(f'~*- Resampled label distribution: ~*{dict(zip(unique_res, counts_res))}', ['normal', 'blue'], advanced_mode=True)

    # Reshape x_train_res back to the original x_train shape
    x_train_res = x_train_res.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[3])

    # Convert y_train_res from label encoding back to one-hot encoding
    y_train_res = to_categorical(y_train_res_label_encoded)

    # Calculate the ratio of two labels after resampling
    pneumonia_count = np.sum(y_train_res[:, 1])
    total_count = y_train_res.shape[0]
    label_ratio_res = pneumonia_count / total_count
    label_ratio_percentage_res = label_ratio_res * 100

    # Replace the original data with the resampled data
    x_train = x_train_res
    y_train = y_train_res

    # Delete the resampled data to free up memory
    del x_train_res, y_train_res_label_encoded, y_train_res
# Generating augmented data
print_Color(f'~*Generating augmented data ~*[~*ADBD: ~*{str(ADBD)}~*]~*...',
            ['yellow', 'cyan', 'green', 'red', 'cyan', 'yellow'],
            advanced_mode=True)
if ADBD > 0:
    for i in range(ADBD):
        # ADB_clip_limit Scheduler>>>
        if i == 0:
            ADB_clip_limit = 1.2
        else:
            #V1>>>
            CL_SLM = 2.4
            ADB_clip_limit = max(2 / (i + 1)**CL_SLM, 0.05)
            # Try it in win graphing calculator copy and paste:
            #  ┌-------------┬--┬---------------┐
            #  │ 𝑦=2/(𝑥+1)^𝑧 ├OR┤ 𝑦=2/(𝑥+1)^2.4 │
            #  └-------------┴--┴---------------┘
            #V2>>>
            # CL_SLM_2 = 1.4
            # CL_SLM_Start_2 = 2
            # ADB_clip_limit = CL_SLM_Start_2/(i+1)**(i+CL_SLM_2) 
            # Try it in win graphing calculator copy and paste:
            #  ┌-----------------┬--┬-------------------┐
            #  │ 𝑦=2/(𝑥+1)^(𝑥+𝑉) ├OR┤ 𝑦=2/(𝑥+1)^(𝑥+1.4) │
            #  └-----------------┴--┴-------------------┘
        print(f'>   Generating ADB[{i+1}/{ADBD}]...')
        # prepare an iterators to scale images
        train_iterator = train_datagen.flow(x_train, y_train, batch_size=len(x_train))

        # get augmented data
        x_train_augmented, y_train_augmented = train_iterator.next()
        print(f'>   ├───Applying adaptive histogram equalization...')
        print(f'>   ├───Adaptive histogram equalization clip limit = {round(ADB_clip_limit, 2)}')
        x_train_augmented = np.clip(x_train_augmented, 0, 255) 
        #print_Color(f'~*>   |---Grayscale range: ~*Min = {np.min(x_train_augmented)}~* | ~*Max = {np.max(x_train_augmented)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)
        x_train_augmented = apply_clahe_rgb_array(x_train_augmented, clip_limit=ADB_clip_limit) # compensating the image info loss
        print(f'>   └───Adding the Generated ADB...')
        # append augmented data to original data
        x_train = np.concatenate([x_train, x_train_augmented])
        y_train = np.concatenate([y_train, y_train_augmented])
        #free up memory
        del y_train_augmented
        del x_train_augmented
# normalizing 
print_Color('Normalizing image data...', ['yellow'])
if adjust_brightness_Mode:
    x_train = adjust_brightness(x_train, np.mean(x_train))
x_train = np.clip(x_train, 0, 255)  
if RANGE_NOM:
    x_train = scale_data_NP(x_train)
y_train = np.array(y_train) 
if Make_EV_DATA:
    x_test = np.clip(x_test, 0, 255)  
    x_val = np.clip(x_val, 0, 255)  
    if RANGE_NOM:
        x_val = scale_data_NP(x_val)
    y_val = np.array(y_val)  
    if RANGE_NOM:
        x_test = scale_data_NP(x_test)
    y_test = np.array(y_test) 
# Check the data type of image data
print_Color(f'~*Data type: ~*{x_train.dtype}', ['normal', 'green'], advanced_mode=True)
# Check the range of image data
print_Color(f'~*RGB Range: ~*Min = {np.min(x_train)}~* | ~*Max = {np.max(x_train)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)
# Calculate the ratio of two labels
if categorical_IMP:
    label_sums = np.sum(y_train, axis=0)
    label_ratio = label_sums / (np.sum(y_train) + 1e-10)
    label_ratio_percentage = label_ratio * 100
    print_Color(f'~*Label ratio: ~*{100 - label_ratio_percentage[0]:.2f}% PNEUMONIA ~*| ~*{label_ratio_percentage[0]:.2f}% NORMAL',
                ['normal', 'red', 'magenta', 'green'], advanced_mode=True)    
print_Color('Setting LNTS...', ['yellow'])
# Get the total number of samples in the arrays
num_samples = x_train.shape[0]
print_Color(f'~*Original num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)
if LNTS != 0:
    print_Color(f'~*Applying LNTS of: ~*{LNTS}', ['normal', 'green'], advanced_mode=True)
    print_Color(f'~*SNC: ~*{num_samples - LNTS}', ['normal', 'green'], advanced_mode=True)
    # Generate random indices to select LNTS samples
    indices = np.random.choice(num_samples, size=LNTS, replace=False)
    # Select the samples using the generated indices
    x_selected = x_train[indices]
    y_selected = y_train[indices]
    x_train = x_selected
    y_train = y_selected
    #free up memory
    del x_selected
    del y_selected
    del indices
    #Debug
    num_samples = x_train.shape[0]
    print_Color(f'~*New num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)
# Shuffle the training data
print_Color('shuffling data...', ['yellow'])
x_train, y_train = shuffle_data(x_train, y_train)
#save_images_to_dir    
if Save_TS:
    print_Color('Saving TS...', ['yellow'])
    SITD = np.random.choice(num_samples, size=400, replace=False)
    S_dir = 'Samples/TSR400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')
    print_Color(f'~*Sample dir: ~*{S_dir}', ['normal', 'green'], advanced_mode=True)
    if RANGE_NOM:
        if scale_data_NP_M:
            save_images_to_dir((x_train[SITD] + 1) / 2.0, y_train[SITD], S_dir)
        else:
            save_images_to_dir(x_train[SITD], y_train[SITD], S_dir)
    else:
        save_images_to_dir(x_train[SITD] / 255, y_train[SITD], S_dir)
print_Color('Done.', ['green'])